{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import re\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_code = \"rw\"\n",
    "language = \"kinyarwanda\"\n",
    "model = f\"lucio/wav2vec2-large-xlsr-{language}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c8ad2fe21bf476889df7b48c6eda3da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=158.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9372e4db28847f0880b3b79e71cefc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=268.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c0005c503ea428b8357ba16f4301ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=138.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85207aaf62494b8bb60aa6ec81770ddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=85.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9038df65b31431ea5c7bd991e82747d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1600.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e437e378a5c404aad25472b2e54795a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1262065047.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(model)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model)\n",
    "model.to(\"cuda\")\n",
    "\n",
    "wer = load_metric(\"wer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Text pre-processing\n",
    "\n",
    "\n",
    "chars_to_ignore_regex = r'[!\"#$%&()*+,./:;<=>?@\\[\\]\\\\_{}|~£¤¨©ª«¬®¯°·¸»¼½¾ðʺ˜˝ˮ‐–—―‚“”„‟•…″‽₋€™−√�]'\n",
    "chars_to_ignore_pattern = re.compile(chars_to_ignore_regex)\n",
    "\n",
    "def remove_special_characters(batch):\n",
    "    batch[\"text\"] = re.sub(r'[ʻʽʼ‘’´`]', r\"'\", batch[\"sentence\"])\n",
    "    batch[\"text\"] = re.sub(chars_to_ignore_regex, \"\", batch[\"text\"]).lower().strip()\n",
    "    batch[\"text\"] = re.sub(r\"(-|' | '|  +)\", \" \", batch[\"text\"])\n",
    "    batch[\"text\"] = unidecode.unidecode(batch[\"text\"])\n",
    "    batch[\"length\"] = len(batch[\"text\"])\n",
    "    return batch\n",
    "\n",
    "\n",
    "## Audio pre-processing\n",
    "resampler = torchaudio.transforms.Resample(48_000, 16_000)\n",
    "\n",
    "def speech_file_to_array_fn(batch):\n",
    "    speech_array, sampling_rate = torchaudio.load(batch[\"path\"])\n",
    "    batch[\"speech\"] = resampler(speech_array).squeeze().numpy()\n",
    "    batch[\"sampling_rate\"] = 16_000\n",
    "    return batch\n",
    "\n",
    "\n",
    "# Text transformation and audio resampling\n",
    "def cv_prepare(batch):\n",
    "    batch = remove_special_characters(batch)\n",
    "    batch = speech_file_to_array_fn(batch)\n",
    "\n",
    "    return batch\n",
    "\n",
    "# Number of CPUs or None\n",
    "num_proc = 8\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset common_voice (/workspace/raw_data/rw/common_voice/rw/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43aa0ebfa8f1460cb3fbe9054fafbee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15724.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_dataset = load_dataset(\"common_voice\", lang_code, split=\"test\", cache_dir=f\"/workspace/raw_data/{lang_code}\")\n",
    "\n",
    "test_dataset = test_dataset.map(cv_prepare, num_proc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca4b6e8c45e64e93b4cff3233f866f70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1966.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate(batch):\n",
    "    inputs = processor(batch[\"speech\"], sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(inputs.input_values.to(\"cuda\"), attention_mask=inputs.attention_mask.to(\"cuda\")).logits\n",
    "\n",
    "    pred_ids = torch.argmax(logits, dim=-1)\n",
    "    batch[\"pred_strings\"] = processor.batch_decode(pred_ids)\n",
    "    return batch\n",
    "\n",
    "result = test_dataset.map(evaluate, batched=True, batch_size=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('', ''): 6831,\n",
       "         ('twenties', 'male'): 3716,\n",
       "         ('twenties', 'female'): 2670,\n",
       "         ('thirties', 'male'): 336,\n",
       "         ('fourties', 'male'): 5,\n",
       "         ('fourties', 'female'): 7,\n",
       "         ('teens', 'other'): 35,\n",
       "         ('teens', 'female'): 1579,\n",
       "         ('twenties', 'other'): 71,\n",
       "         ('teens', 'male'): 474})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(zip(test_dataset['age'], test_dataset['gender']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: 46.040170\n"
     ]
    }
   ],
   "source": [
    "# WER Metric computation\n",
    "\n",
    "import jiwer\n",
    "\n",
    "def chunked_wer(targets, predictions, chunk_size=None):                                          \n",
    "    if chunk_size is None: return jiwer.wer(targets, predictions)                                \n",
    "    start = 0                                                                                    \n",
    "    end = chunk_size                                                                             \n",
    "    H, S, D, I = 0, 0, 0, 0                                                                      \n",
    "    while start < len(targets):                                                                  \n",
    "        chunk_metrics = jiwer.compute_measures(targets[start:end], predictions[start:end])       \n",
    "        H = H + chunk_metrics[\"hits\"]                                                            \n",
    "        S = S + chunk_metrics[\"substitutions\"]                                                   \n",
    "        D = D + chunk_metrics[\"deletions\"]                                                       \n",
    "        I = I + chunk_metrics[\"insertions\"]                                                      \n",
    "        start += chunk_size                                                                      \n",
    "        end += chunk_size                                                                        \n",
    "    return float(S + D + I) / float(H + S + D)\n",
    "\n",
    "print(\"WER: {:2f}\".format(100 * chunked_wer(result[\"text\"], result[\"pred_strings\"], chunk_size=4000)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07dc143653204c65a620cf83e7142d51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=16.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Female data WER: 36.208978\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ce71f60ca5c418b96555821ca099c30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=16.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Male data WER: 46.595275\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "693b5f1691064a71b2e12dc2779715ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=16.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "UNK gender data WER: 52.137815\n"
     ]
    }
   ],
   "source": [
    "female_result = result.filter(lambda example: example[\"gender\"] == \"female\")\n",
    "print(\"Female data WER: {:2f}\".format(100 * chunked_wer(predictions=female_result[\"pred_strings\"], targets=female_result[\"text\"], chunk_size=4000)))\n",
    "\n",
    "male_result = result.filter(lambda example: example[\"gender\"] == \"male\")\n",
    "print(\"Male data WER: {:2f}\".format(100 * chunked_wer(predictions=male_result[\"pred_strings\"], targets=male_result[\"text\"], chunk_size=4000)))\n",
    "\n",
    "unk_result = result.filter(lambda example: example[\"gender\"] == \"\")\n",
    "print(\"UNK gender data WER: {:2f}\".format(100 * chunked_wer(predictions=unk_result[\"pred_strings\"], targets=unk_result[\"text\"], chunk_size=4000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"yaherukaga gukora igitaramo nk'iki mu mujyi wa namur mu bubiligi \",\n",
       "  'yaherukagu gukora igitaramo yuki mugi wa na nkurmu biliki'),\n",
       " ('ibi rero ntibizashoboka kandi nawe arabizi ',\n",
       "  \"inyo rero ntibizashoboka guhandi n'unkurabizi\"),\n",
       " ('yakomeje agira ati turateganya ko hazakomeza kubaho no mu myaka izakurikira ',\n",
       "  'yakomeje agira ati turateganya ko azakomeza kubaho no mu myaka izakurikira'),\n",
       " ('iki kigo cyakira abaturage bo mu turere twa gisagara mu mirenge ya kigembe na nyanza ',\n",
       "  'iti kiga cyakira abaturage bo mu turere twagisagara umirinde ya kigemde na nyanza'),\n",
       " ('mama yambyukije murukerera ', 'nyuma yapyukije mu ikerera'),\n",
       " ('uwo muhungu wamubikiraga aravuga ati komera ',\n",
       "  'uwo muhungu wamubikiraga aravuga ati komera k'),\n",
       " ('friso wamaze igihe kingana gityo ataragarura ubwenge ',\n",
       "  'firiso wamaze igihe kingana gutyo ataragarura ubwenge'),\n",
       " ('ndetse ngo namwifurize umunsi mwiza ',\n",
       "  'ndetse ngo namwifurije umunsi mwiza'),\n",
       " (\"kw'ibumoso \", \"w'ibukozo\"),\n",
       " ('kanda hano wumve indirimbo meze neza ',\n",
       "  'kanda hano bumve indirimbo meze neza')]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(result[:10]['text'], result[:10]['pred_strings']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221154620c95429fb8282e7303fdd75b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=16.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "good data WER: 43.545790\n"
     ]
    }
   ],
   "source": [
    "unk_result = result.filter(lambda example: example[\"down_votes\"] == 0)\n",
    "print(\"good data WER: {:2f}\".format(100 * chunked_wer(predictions=unk_result[\"pred_strings\"], targets=unk_result[\"text\"], chunk_size=4000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_all_chars(batch):\n",
    "    all_text = \" \".join(batch[\"text\"])\n",
    "    vocab = list(set(all_text))\n",
    "    return {\"vocab\": [vocab], \"all_text\": [all_text]}\n",
    "\n",
    "def strip_accents(batch):\n",
    "   batch[\"sentence\"] = unidecode.unidecode(batch[\"sentence\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset common_voice (/workspace/raw_data/rw/common_voice/rw/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23a90d0136744c3fb1466509d622196f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#2', max=3758.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f766d0cb1f9340c68e033322e83ffe2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#3', max=3758.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95fb3deb1160421e8b6b9224e6234719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#1', max=3758.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c89393da19e8472db402a416e0c77857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#0', max=3758.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "valid_dataset = load_dataset(\"common_voice\", \"rw\", split=\"validation\", cache_dir=\"/workspace/raw_data/rw\")\n",
    "valid_dataset = valid_dataset.map(remove_special_characters, remove_columns=['path'], num_proc=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15032,\n",
       " {'accent': '',\n",
       "  'age': 'teens',\n",
       "  'client_id': '5e85947436bbc805e503bf926beb533b07da07cef77c491a476c8cd1d9bce7b9a4cdc8171564447ea1d2c9c591a203b2e37545a4c8a8f7d0b2881e9e64441e5b',\n",
       "  'down_votes': 1,\n",
       "  'gender': 'male',\n",
       "  'locale': 'rw',\n",
       "  'segment': \"''\",\n",
       "  'sentence': 'Umuntungo we ntabwo aba agomba kuwumarira mu gushakisha imyenda yo kwambara.',\n",
       "  'text': 'umuntungo we ntabwo aba agomba kuwumarira mu gushakisha imyenda yo kwambara ',\n",
       "  'up_votes': 2})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_dataset), valid_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset common_voice (/workspace/raw_data/rw/common_voice/rw/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /workspace/raw_data/rw/common_voice/rw/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-f26b4b6f0d41515a.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /workspace/raw_data/rw/common_voice/rw/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-2064fc16cd638593.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /workspace/raw_data/rw/common_voice/rw/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-ce61ebe019cae2d3.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /workspace/raw_data/rw/common_voice/rw/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-8cec50e0a7e00cde.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_dataset(\"common_voice\", \"rw\", split=\"train\", cache_dir=\"/workspace/raw_data/rw\")\n",
    "train_dataset = train_dataset.map(remove_special_characters, remove_columns=['path'], num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94eae1b731104941b520bb2045a2f8fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=516.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "442503"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data = train_dataset.filter(lambda x: x['down_votes'] == 0)\n",
    "len(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(515197,\n",
       " {'accent': '',\n",
       "  'age': 'twenties',\n",
       "  'client_id': 'd4439c64c8f13b84cd2ce31d5d9eeae2a81147d89abb00cebaaf11b60b7166c24dd257a44e73c72c73c93cae29d904bed135824aca06e5970e001e9406e8a891',\n",
       "  'down_votes': 0,\n",
       "  'gender': 'male',\n",
       "  'length': 38,\n",
       "  'locale': 'rw',\n",
       "  'segment': \"''\",\n",
       "  'sentence': 'kugira ngo inama za komisiyo ziterane',\n",
       "  'text': 'kugira ngo inama za komisiyo ziterane ',\n",
       "  'up_votes': 2})"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), clean_data[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dataset), max(test_dataset['length']), len(test_dataset[0]['speech']), test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(515197,\n",
       " 50.70219352985363,\n",
       " {'accent': '',\n",
       "  'age': 'twenties',\n",
       "  'client_id': 'd4439c64c8f13b84cd2ce31d5d9eeae2a81147d89abb00cebaaf11b60b7166c24dd257a44e73c72c73c93cae29d904bed135824aca06e5970e001e9406e8a891',\n",
       "  'down_votes': 1,\n",
       "  'gender': 'male',\n",
       "  'length': 53,\n",
       "  'locale': 'rw',\n",
       "  'segment': \"''\",\n",
       "  'sentence': 'akunda u rwanda cyane cyane ku byerekeye isuku ihaba',\n",
       "  'text': 'akunda u rwanda cyane cyane ku byerekeye isuku ihaba ',\n",
       "  'up_votes': 2})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset), sum(test_dataset['length'])/len(test_dataset), test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'valid_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-ece183a4cbb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'age'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gender'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'valid_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "from collections import Counter \n",
    "\n",
    "Counter(zip(valid_dataset['age'], valid_dataset['gender']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('twenties', 'male'): 117836,\n",
       "         ('teens', 'female'): 32882,\n",
       "         ('thirties', 'male'): 49188,\n",
       "         ('twenties', ''): 39584,\n",
       "         ('thirties', 'female'): 18498,\n",
       "         ('twenties', 'female'): 128450,\n",
       "         ('teens', 'male'): 53338,\n",
       "         ('', ''): 2727})"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(zip(clean_data['age'], clean_data['gender']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a063993c42b4550906db4e94bc71aad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vocab = train_dataset.map(\n",
    "    extract_all_chars,\n",
    "    batched=True,\n",
    "    batch_size=-1,\n",
    "    keep_in_memory=True,\n",
    "    remove_columns=train_dataset.column_names,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-1f8b23a1e3a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m vocab_test = test_dataset.map(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mextract_all_chars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mkeep_in_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "vocab_test = test_dataset.map(\n",
    "    extract_all_chars,\n",
    "    batched=True,\n",
    "    batch_size=-1,\n",
    "    keep_in_memory=True,\n",
    "    remove_columns=test_dataset.column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'a': 3648720,\n",
       "         'k': 991786,\n",
       "         'u': 1878946,\n",
       "         'n': 1462878,\n",
       "         'd': 287040,\n",
       "         ' ': 4185822,\n",
       "         'r': 1332884,\n",
       "         'w': 654944,\n",
       "         'c': 179634,\n",
       "         'y': 998491,\n",
       "         'e': 1489157,\n",
       "         'b': 1266316,\n",
       "         'i': 2363305,\n",
       "         's': 555158,\n",
       "         'h': 569783,\n",
       "         'm': 1030066,\n",
       "         'l': 74865,\n",
       "         'z': 499214,\n",
       "         'g': 847924,\n",
       "         'f': 100863,\n",
       "         'j': 135886,\n",
       "         'o': 1129970,\n",
       "         't': 619214,\n",
       "         \"'\": 155269,\n",
       "         'v': 97299,\n",
       "         'p': 78286,\n",
       "         'x': 1681,\n",
       "         'q': 1413})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "cnts = Counter(vocab[0]['all_text'])\n",
    "cnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('c', 11),\n",
       " ('e', 53),\n",
       " ('a', 34),\n",
       " ('o', 80),\n",
       " ('i', 62),\n",
       " ('e', 32),\n",
       " ('i', 75),\n",
       " ('', 1),\n",
       " ('oe', 15),\n",
       " ('s', 6),\n",
       " ('s', 5),\n",
       " ('n', 6),\n",
       " ('', 7),\n",
       " ('c', 93),\n",
       " ('a', 26),\n",
       " ('e', 3),\n",
       " ('a', 5),\n",
       " ('v', 4),\n",
       " ('o', 20),\n",
       " ('i', 69),\n",
       " ('u', 29),\n",
       " ('u', 84),\n",
       " ('o', 45),\n",
       " ('y', 4),\n",
       " ('i', 15),\n",
       " (\"s'\", 2),\n",
       " ('a', 98),\n",
       " ('g', 5),\n",
       " ('u', 34),\n",
       " ('u', 1),\n",
       " ('e', 30),\n",
       " ('l', 3),\n",
       " ('u', 7),\n",
       " ('o', 57),\n",
       " ('o', 5),\n",
       " ('h', 6),\n",
       " ('i', 2),\n",
       " ('i', 3),\n",
       " ('o', 2),\n",
       " ('ss', 1),\n",
       " ('ae', 4),\n",
       " ('z', 2),\n",
       " ('k', 5),\n",
       " ('c', 4),\n",
       " ('z', 2),\n",
       " ('i', 9),\n",
       " ('r', 1),\n",
       " ('', 1),\n",
       " ('m', 1),\n",
       " ('s', 1),\n",
       " ('a', 3),\n",
       " ('u', 7),\n",
       " ('o', 2),\n",
       " ('ie', 1),\n",
       " ('e', 1),\n",
       " ('i', 2),\n",
       " ('a', 1),\n",
       " ('t', 1),\n",
       " ('b', 1),\n",
       " ('ae', 1),\n",
       " ('sh', 1),\n",
       " ('a', 1),\n",
       " ('o', 2),\n",
       " ('u', 1),\n",
       " ('z', 1),\n",
       " ('f', 1),\n",
       " ('fi', 1),\n",
       " ('', 2)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unidecode\n",
    "[(unidecode.unidecode(k), cnts[k]) for k in cnts if cnts[k] < 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('akunda u rwanda cyane cyane ku byerekeye isuku ihaba',\n",
       "  'akunda u rwanda cyane cyane ku byerekeye isuku ihaba '),\n",
       " ('cy icyuma kandi libani izagwa f igushijwe n umunyambaraga',\n",
       "  'cy icyuma kandi libani izagwa f igushijwe n umunyambaraga '),\n",
       " ('mu nkuge babijugunya mu nyanja ngo boroshye',\n",
       "  'mu nkuge babijugunya mu nyanja ngo boroshye '),\n",
       " ('ubwoko bw ibikorwa isosiyete ifitemo',\n",
       "  'ubwoko bw ibikorwa isosiyete ifitemo '),\n",
       " ('uti «ubutungane bwanjye ni bwo bwateye uhoraho kunzana muri iki gihugu ngo nkigarurire. ubwigomeke bw’ayo mahanga ni bwo bwateye uhoraho kubanyaga ibyabo ngo abiguhe.',\n",
       "  \"uti ubutungane bwanjye ni bwo bwateye uhoraho kunzana muri iki gihugu ngo nkigarurire ubwigomeke bw'ayo mahanga ni bwo bwateye uhoraho kubanyaga ibyabo ngo abiguhe \"),\n",
       " ('maso hanjye ho nta wushobora kuhabona',\n",
       "  'maso hanjye ho nta wushobora kuhabona '),\n",
       " ('nsenga maze umumarayika arambwira ngo ngutumeho',\n",
       "  'nsenga maze umumarayika arambwira ngo ngutumeho '),\n",
       " ('mbere ku isoko ry imari n imigabane',\n",
       "  'mbere ku isoko ry imari n imigabane '),\n",
       " ('umwami w’i hasori abyumvise arumirwa',\n",
       "  \"umwami w'i hasori abyumvise arumirwa \"),\n",
       " ('hari igihe wakumva ko bakabije kugira impungenge',\n",
       "  'hari igihe wakumva ko bakabije kugira impungenge '),\n",
       " ('umurenge wa save akagari ka zivu bawukuyeho',\n",
       "  'umurenge wa save akagari ka zivu bawukuyeho '),\n",
       " ('yicisha yakobo inkota mwene se wa yohana',\n",
       "  'yicisha yakobo inkota mwene se wa yohana '),\n",
       " ('mu gihe cyo kwemerwa', 'mu gihe cyo kwemerwa '),\n",
       " ('uburenganzira bw’utanze ingwate mu gutanga ayo',\n",
       "  \"uburenganzira bw'utanze ingwate mu gutanga ayo \"),\n",
       " ('nzozi n icyo zisobanura', 'nzozi n icyo zisobanura '),\n",
       " ('hari ibiganiro ku ubukungu hagati ya guverinoma zombi',\n",
       "  'hari ibiganiro ku ubukungu hagati ya guverinoma zombi '),\n",
       " ('abanyamuryango b icyubahiro', 'abanyamuryango b icyubahiro '),\n",
       " ('tuba twiteguye kubafasha kubera ko tuba twaragiranye ubucuti bukomeye imigani',\n",
       "  'tuba twiteguye kubafasha kubera ko tuba twaragiranye ubucuti bukomeye imigani '),\n",
       " ('aho bibaye ngombwa uretse inyubako yo kubamo',\n",
       "  'aho bibaye ngombwa uretse inyubako yo kubamo '),\n",
       " ('imitako igirahantu neza.', 'imitako igirahantu neza '),\n",
       " ('nuko rero ukuboko k uwiteka kwaremereraga',\n",
       "  'nuko rero ukuboko k uwiteka kwaremereraga '),\n",
       " ('abagambirira ibyiza bazabona imbabazi n umurava',\n",
       "  'abagambirira ibyiza bazabona imbabazi n umurava '),\n",
       " ('umuherezabitambo azahagarare imbere,',\n",
       "  'umuherezabitambo azahagarare imbere '),\n",
       " ('we wubatse irembo rya ruguru ry inzu ya yehova',\n",
       "  'we wubatse irembo rya ruguru ry inzu ya yehova '),\n",
       " ('akarokora ubwoko bwe akabuvana mu maboko y abanyegiputa',\n",
       "  'akarokora ubwoko bwe akabuvana mu maboko y abanyegiputa '),\n",
       " ('twese hamwe n ibyunvikanweho n ibisabwa tuzabishobora',\n",
       "  'twese hamwe n ibyunvikanweho n ibisabwa tuzabishobora '),\n",
       " ('iteka rya minisitiri w intebe ryemerera kujya mu kiruhuko cy izabukuru',\n",
       "  'iteka rya minisitiri w intebe ryemerera kujya mu kiruhuko cy izabukuru '),\n",
       " ('ugomba kugira inzu nini.', 'ugomba kugira inzu nini '),\n",
       " ('teariki aravuga ati ni byo', 'teariki aravuga ati ni byo '),\n",
       " ('imanza ze zose zirakiranuka', 'imanza ze zose zirakiranuka '),\n",
       " ('gira umwete wo kuza munzu igihe cy imbeho kirageze',\n",
       "  'gira umwete wo kuza munzu igihe cy imbeho kirageze '),\n",
       " ('gukora raporo y‘ibyakozwe ku gihe', \"gukora raporo y'ibyakozwe ku gihe \"),\n",
       " ('iyo urwego rushinzwe ubugenzuzi rwanze',\n",
       "  'iyo urwego rushinzwe ubugenzuzi rwanze '),\n",
       " ('u rwanda rwahawe inkunga ingana na miliyari ebyiri za madorari',\n",
       "  'u rwanda rwahawe inkunga ingana na miliyari ebyiri za madorari '),\n",
       " ('ku busabe nk ubwo urukiko rubifitiye ububasha',\n",
       "  'ku busabe nk ubwo urukiko rubifitiye ububasha '),\n",
       " ('imyanda ikomoka ku bikoresho', 'imyanda ikomoka ku bikoresho '),\n",
       " ('n ibyaha bifitanye isano na yo no gufatanya n inzego za leta n iz abikorera kubaka',\n",
       "  'n ibyaha bifitanye isano na yo no gufatanya n inzego za leta n iz abikorera kubaka '),\n",
       " ('nta sosiyeti yemerewe gutanga amakuru',\n",
       "  'nta sosiyeti yemerewe gutanga amakuru '),\n",
       " ('uko bikwiye ibidukikije bibangamiye iterambere',\n",
       "  'uko bikwiye ibidukikije bibangamiye iterambere '),\n",
       " ('amahoro araharanirwa akubakwa kandi akarindwa ibi bizatuma jenoside itongera kubaho',\n",
       "  'amahoro araharanirwa akubakwa kandi akarindwa ibi bizatuma jenoside itongera kubaho '),\n",
       " ('nubwo amafaranga ari ay ingenzi', 'nubwo amafaranga ari ay ingenzi '),\n",
       " ('uburemere bw ifeza y ibitereko by amatara n amatara yabyo hakurikijwe icyo ibitereko',\n",
       "  'uburemere bw ifeza y ibitereko by amatara n amatara yabyo hakurikijwe icyo ibitereko '),\n",
       " ('ibyiza ni uko mwababazwa babah ra gukora',\n",
       "  'ibyiza ni uko mwababazwa babah ra gukora '),\n",
       " ('nahindutse urwamenyo mu bwoko bwanjye.',\n",
       "  'nahindutse urwamenyo mu bwoko bwanjye '),\n",
       " ('turi ku musozi wa horebu', 'turi ku musozi wa horebu '),\n",
       " ('kuko bazanywe no gutata igihugu cyose.',\n",
       "  'kuko bazanywe no gutata igihugu cyose '),\n",
       " ('bafite ibiruta ibyo umutima w’umuntu',\n",
       "  \"bafite ibiruta ibyo umutima w'umuntu \"),\n",
       " ('j ibyo yehova yari yarababwiye ati ntimugakore ikintu nk icyo',\n",
       "  'j ibyo yehova yari yarababwiye ati ntimugakore ikintu nk icyo '),\n",
       " ('igihugu cy’imigezi n’amasoko, cy’amazi ari mu nda y’ubutaka akadudubiza mu bibaya no ku misozi,',\n",
       "  \"igihugu cy'imigezi n'amasoko cy'amazi ari mu nda y'ubutaka akadudubiza mu bibaya no ku misozi \"),\n",
       " ('nta kintu yakira atari ku kazi ruswa amaturo inyiturano',\n",
       "  'nta kintu yakira atari ku kazi ruswa amaturo inyiturano '),\n",
       " ('runaka ifite ku murongo w ibyigwa', 'runaka ifite ku murongo w ibyigwa '),\n",
       " ('uko zihuriza hamwe kandi zikuzuzanya',\n",
       "  'uko zihuriza hamwe kandi zikuzuzanya '),\n",
       " ('muri abo bantu benshi harimo umugabo nari narabwirije yagize ubutwari bwo kubabwira ati nimumubabarire',\n",
       "  'muri abo bantu benshi harimo umugabo nari narabwirije yagize ubutwari bwo kubabwira ati nimumubabarire '),\n",
       " ('urebana impuhwe azabona imigisha kuko yahaye uworoheje ibyo kurya',\n",
       "  'urebana impuhwe azabona imigisha kuko yahaye uworoheje ibyo kurya '),\n",
       " ('nyandiko uwimukanwa n utimukanwa', 'nyandiko uwimukanwa n utimukanwa '),\n",
       " ('byawe byangwa urunuka n ibizira byawe byose ni',\n",
       "  'byawe byangwa urunuka n ibizira byawe byose ni '),\n",
       " ('nuko salomo ahagarara imbere y igicaniro cya yehova n imbere y iteraniro ryose',\n",
       "  'nuko salomo ahagarara imbere y igicaniro cya yehova n imbere y iteraniro ryose '),\n",
       " ('ishyikirizwa inama rusange y umuryango',\n",
       "  'ishyikirizwa inama rusange y umuryango '),\n",
       " ('mu nzu ya yehova haba amahoro', 'mu nzu ya yehova haba amahoro '),\n",
       " ('ikirego gitangwa n umwana', 'ikirego gitangwa n umwana '),\n",
       " ('umudugudu akagari umurenge akarere n’intara',\n",
       "  \"umudugudu akagari umurenge akarere n'intara \"),\n",
       " ('leta abashyize umukono kuri aya mategekoshingiro bashyizeho umuryango nyarwanda',\n",
       "  'leta abashyize umukono kuri aya mategekoshingiro bashyizeho umuryango nyarwanda '),\n",
       " ('imbere ndeste n icyayimenyekanisha', 'imbere ndeste n icyayimenyekanisha '),\n",
       " ('icyaha kitahanaguwe n imbabazi z itegeko cyangwa',\n",
       "  'icyaha kitahanaguwe n imbabazi z itegeko cyangwa '),\n",
       " ('bazamara imyaka irindwi bakizitwika',\n",
       "  'bazamara imyaka irindwi bakizitwika '),\n",
       " ('yahinduye imirimo biteganijwe n ingero zimukuriye.',\n",
       "  'yahinduye imirimo biteganijwe n ingero zimukuriye '),\n",
       " ('w umuryango mu gihe usheshwe n ububasha',\n",
       "  'w umuryango mu gihe usheshwe n ububasha '),\n",
       " ('bagomba kandi guha umwana umuti wa nevirapine',\n",
       "  'bagomba kandi guha umwana umuti wa nevirapine '),\n",
       " ('abisabye bishobora kandi gutangwa binyuze',\n",
       "  'abisabye bishobora kandi gutangwa binyuze '),\n",
       " ('igicaniro cy amabuye kuri ebali', 'igicaniro cy amabuye kuri ebali '),\n",
       " ('cyaba gisa n’ibiri hejuru mu kirere cyangwa n’ibiri hasi ku isi,',\n",
       "  \"cyaba gisa n'ibiri hejuru mu kirere cyangwa n'ibiri hasi ku isi \"),\n",
       " ('urwego rubishinzwe ku bufatanye n’urwego rukuru',\n",
       "  \"urwego rubishinzwe ku bufatanye n'urwego rukuru \"),\n",
       " ('rwamagana kurema amatsinda avura ihungabana gasabo na nyarugenge kugaragaza',\n",
       "  'rwamagana kurema amatsinda avura ihungabana gasabo na nyarugenge kugaragaza '),\n",
       " ('ry imiyoboro y icyitegererezo ry ufite uruhushya',\n",
       "  'ry imiyoboro y icyitegererezo ry ufite uruhushya '),\n",
       " ('cyangwa buri gihembwe icyakora hashobora',\n",
       "  'cyangwa buri gihembwe icyakora hashobora '),\n",
       " ('reka tujye mu butayu tugendemo urugendo',\n",
       "  'reka tujye mu butayu tugendemo urugendo '),\n",
       " ('biguzwe cyangwa bigurishijwe nanjye',\n",
       "  'biguzwe cyangwa bigurishijwe nanjye '),\n",
       " ('urugero simoni petero yabwiye yesu ati uri kristo matayo',\n",
       "  'urugero simoni petero yabwiye yesu ati uri kristo matayo '),\n",
       " ('bohereza amabuye y agaciromu mahanga',\n",
       "  'bohereza amabuye y agaciromu mahanga '),\n",
       " ('bw iyishyurana inyandiko z umwimerere',\n",
       "  'bw iyishyurana inyandiko z umwimerere '),\n",
       " ('y icyateza ingorane ku mikorere', 'y icyateza ingorane ku mikorere '),\n",
       " ('abamoni bazaba nka gomora', 'abamoni bazaba nka gomora '),\n",
       " ('bose bari abatware', 'bose bari abatware '),\n",
       " ('mu gihe cy imyaka itanu hashingiwe ku itegeko',\n",
       "  'mu gihe cy imyaka itanu hashingiwe ku itegeko '),\n",
       " ('ibyo bikunda kuba ku bakobwa', 'ibyo bikunda kuba ku bakobwa '),\n",
       " ('abarimu maze kubahaga imikoro yo ku za gukora',\n",
       "  'abarimu maze kubahaga imikoro yo ku za gukora '),\n",
       " ('umwenda n isosiyete y ubufatanye', 'umwenda n isosiyete y ubufatanye '),\n",
       " ('umuryango nyarwanda utari uwa leta kimara',\n",
       "  'umuryango nyarwanda utari uwa leta kimara '),\n",
       " ('kungurana ibitekerezo binyuze mu biganiro bihoraho',\n",
       "  'kungurana ibitekerezo binyuze mu biganiro bihoraho '),\n",
       " ('inzira zihatira ishyirwa mu bikorwa',\n",
       "  'inzira zihatira ishyirwa mu bikorwa '),\n",
       " ('iby impinduka zibaye mu byerekeye abafite',\n",
       "  'iby impinduka zibaye mu byerekeye abafite '),\n",
       " ('bahasanze ibisigazwa by’intama ihene n’inka',\n",
       "  \"bahasanze ibisigazwa by'intama ihene n'inka \"),\n",
       " ('mu buvumo buri mu isambu y i makipela iri',\n",
       "  'mu buvumo buri mu isambu y i makipela iri '),\n",
       " ('niwatuza akanwa kawe yuko yesu ari umwami',\n",
       "  'niwatuza akanwa kawe yuko yesu ari umwami '),\n",
       " ('byabanje kuza ari bike ariko nyuma haza byinshi ababwiriza',\n",
       "  'byabanje kuza ari bike ariko nyuma haza byinshi ababwiriza '),\n",
       " ('igice cya kabiri', 'igice cya kabiri '),\n",
       " ('u rwanda rumaze kwa mamara mu ruhando mpuzamahanga',\n",
       "  'u rwanda rumaze kwa mamara mu ruhando mpuzamahanga '),\n",
       " ('amaze kuvuga ibyo umufarisayo aramutumira ngo aze',\n",
       "  'amaze kuvuga ibyo umufarisayo aramutumira ngo aze '),\n",
       " ('amazu y ubwami n amazu akoreramo ibiro by amashami',\n",
       "  'amazu y ubwami n amazu akoreramo ibiro by amashami '),\n",
       " ('impamyabushobozi mu bijyanye n ubukungu',\n",
       "  'impamyabushobozi mu bijyanye n ubukungu ')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(train_dataset['sentence'][:100], train_dataset['text'][:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'COMBINING ACUTE TONE MARK'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata\n",
    "unicodedata.name('́')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': 0,\n",
       " 'd': 1,\n",
       " 's': 2,\n",
       " 'n': 3,\n",
       " 'c': 4,\n",
       " 'l': 5,\n",
       " 'h': 6,\n",
       " 'w': 7,\n",
       " 'u': 8,\n",
       " 'z': 9,\n",
       " 't': 11,\n",
       " 'g': 12,\n",
       " 'j': 13,\n",
       " 'm': 14,\n",
       " 'o': 15,\n",
       " 'e': 16,\n",
       " 'k': 17,\n",
       " 'r': 18,\n",
       " 'i': 19,\n",
       " 'b': 20,\n",
       " 'f': 21,\n",
       " 'a': 22,\n",
       " 'v': 23,\n",
       " 'p': 24,\n",
       " '|': 10,\n",
       " '[UNK]': 25,\n",
       " '[PAD]': 26,\n",
       " '<s>': 27,\n",
       " '</s>': 28}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "import os\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/checkpoints/lg/wav2vec2-large-xlsr-lg-augment/checkpoint-4096'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_last_checkpoint(\"/workspace/checkpoints/lg/wav2vec2-large-xlsr-lg-augment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir=\"/workspace/checkpoints/lg/wav2vec2-large-xlsr-lg-augment/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for last checkpoint in /workspace/checkpoints/lg/wav2vec2-large-xlsr-lg-augment/\n",
      "Checkpoint detected, resuming training at /workspace/checkpoints/lg/wav2vec2-large-xlsr-lg-augment/checkpoint-4096. To avoid this behavior, change the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\n"
     ]
    }
   ],
   "source": [
    "last_checkpoint = None\n",
    "if os.path.isdir(output_dir) and True and not False:\n",
    "    print(f\"Looking for last checkpoint in {output_dir}\")\n",
    "    last_checkpoint = get_last_checkpoint(output_dir)\n",
    "    if last_checkpoint is None and len(os.listdir(output_dir)) > 0:\n",
    "        raise ValueError(\n",
    "            f\"Output directory ({output_dir}) already exists and is not empty. \"\n",
    "            \"Use --overwrite_output_dir to overcome.\"\n",
    "        )\n",
    "    elif last_checkpoint is not None:\n",
    "        print(\n",
    "            f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"\n",
    "            \"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isdir(output_dir) and True and not False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import torchaudio\n",
    "import soundfile\n",
    "from audiomentations import Compose, AddGaussianNoise, Gain, PitchShift, Shift\n",
    "\n",
    "resampler = torchaudio.transforms.Resample(48_000, 16_000)\n",
    "\n",
    "augment = Compose([\n",
    "    AddGaussianNoise(min_amplitude=0.0001, max_amplitude=0.01, p=1),\n",
    "    PitchShift(min_semitones=-3, max_semitones=3, p=0.8),\n",
    "    Gain(min_gain_in_db=-6, max_gain_in_db=6, p=0.8),\n",
    "    Shift(min_fraction=-0.5, max_fraction=0.5, p=0.8),\n",
    "])\n",
    "\n",
    "def speech_file_to_array_fn_torchaudio(batch):\n",
    "    speech_array, sampling_rate = torchaudio.load(batch[\"path\"])\n",
    "    batch[\"speech\"] = resampler(speech_array).squeeze().numpy()\n",
    "    batch[\"sampling_rate\"] = 16_000\n",
    "    return batch\n",
    "\n",
    "def speech_file_to_array_fn_librosa(batch):\n",
    "    speech_array, sample_rate = torchaudio.load(batch[\"path\"])\n",
    "    batch[\"speech\"] = librosa.resample(speech_array.squeeze().numpy(), sample_rate, 16_000)\n",
    "    return batch\n",
    "\n",
    "def augmented_speech_file_to_array_fn(batch):\n",
    "    try:\n",
    "        speech_array, sampling_rate = soundfile.read(batch[\"path\"] + \"-augmented.wav\")\n",
    "    except:\n",
    "        speech_array, sampling_rate = torchaudio.load(batch[\"path\"])\n",
    "        speech_array = resampler(speech_array)\n",
    "        speech_array = augment(samples=speech_array, sample_rate=sampling_rate).squeeze()\n",
    "        soundfile.write(batch[\"path\"]+\"-augmented.wav\", speech_array, sampling_rate, subtype='PCM_24')\n",
    "\n",
    "    batch[\"speech\"] = speech_array\n",
    "    batch[\"sampling_rate\"] = 16_000\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accent': '',\n",
       " 'age': '',\n",
       " 'client_id': 'a0c75a2b3ef19a055ebcc7587ebf341614373519ceb63f67e67e4eae0eb4858dc2031cd42b08b389168e6c84bce198dc8f7405fdb443195eaaf6cd7dc981425c',\n",
       " 'down_votes': 1,\n",
       " 'gender': '',\n",
       " 'locale': 'rw',\n",
       " 'path': '/workspace/raw_data/rw/downloads/extracted/6755b117c96a17977cf94d8a118d06e13daa8d123092dfaa6ccb5bd13f06e60f/cv-corpus-6.1-2020-12-11/rw/clips/common_voice_rw_22948194.mp3',\n",
       " 'segment': \"''\",\n",
       " 'sentence': 'ni uko batari bagiha agaciro isanduku n’ibyo yavuze ku ri bo',\n",
       " 'up_votes': 2,\n",
       " 'speech': array([ 0.        ,  0.        ,  0.        , ..., -0.00116267,\n",
       "        -0.00045365, -0.00068105], dtype=float32)}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speech_file_to_array_fn_librosa(test_dataset[23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accent': '',\n",
       " 'age': '',\n",
       " 'client_id': 'a0c75a2b3ef19a055ebcc7587ebf341614373519ceb63f67e67e4eae0eb4858dc2031cd42b08b389168e6c84bce198dc8f7405fdb443195eaaf6cd7dc981425c',\n",
       " 'down_votes': 1,\n",
       " 'gender': '',\n",
       " 'locale': 'rw',\n",
       " 'path': '/workspace/raw_data/rw/downloads/extracted/6755b117c96a17977cf94d8a118d06e13daa8d123092dfaa6ccb5bd13f06e60f/cv-corpus-6.1-2020-12-11/rw/clips/common_voice_rw_22948195.mp3',\n",
       " 'segment': \"''\",\n",
       " 'sentence': 'amata kwera zari zikeye mu maso kurusha',\n",
       " 'up_votes': 2,\n",
       " 'speech': array([-0.43122205, -0.42071682, -0.4279239 , ..., -0.4282133 ,\n",
       "        -0.4141648 , -0.3871291 ], dtype=float32),\n",
       " 'sampling_rate': 16000}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_speech_file_to_array_fn(test_dataset[24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05630261, -0.03208497, -0.05551476, ...,  0.00743804,\n",
       "       -0.00030689, -0.08274259], dtype=float32)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_speech_file_to_array_fn(test_dataset[24])['speech'].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a1c616bb5a4d68add6c51777b82b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4717.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-152-61b66947f401>\u001b[0m in \u001b[0;36maugmented_speech_file_to_array_fn\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0;31m#speech_array, sampling_rate = soundfile.read(batch[\"path\"] + \"-augmented.wav\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-156-ff6de73deca8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maugmented_speech_file_to_array_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint)\u001b[0m\n\u001b[1;32m   1425\u001b[0m                 \u001b[0mfn_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1426\u001b[0m                 \u001b[0mnew_fingerprint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_fingerprint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1427\u001b[0;31m                 \u001b[0mupdate_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdate_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1428\u001b[0m             )\n\u001b[1;32m   1429\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m         }\n\u001b[1;32m    202\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;31m# re-apply format to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/fingerprint.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Call actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;31m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_map_single\u001b[0;34m(self, function, with_indices, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, update_data)\u001b[0m\n\u001b[1;32m   1682\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1684\u001b[0;31m                         \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_function_on_filtered_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1685\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mupdate_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1686\u001b[0m                             \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast_to_python_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mapply_function_on_filtered_inputs\u001b[0;34m(inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   1606\u001b[0m                 \u001b[0meffective_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m             processed_inputs = (\n\u001b[0;32m-> 1608\u001b[0;31m                 \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meffective_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mwith_indices\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1609\u001b[0m             )\n\u001b[1;32m   1610\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mupdate_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-152-61b66947f401>\u001b[0m in \u001b[0;36maugmented_speech_file_to_array_fn\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mspeech_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mspeech_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeech_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mspeech_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspeech_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampling_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0msoundfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"-augmented.wav\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspeech_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'PCM_24'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/audiomentations/core/composition.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, samples, sample_rate)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/audiomentations/core/transforms_interface.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, samples, sample_rate)\u001b[0m\n\u001b[1;32m     74\u001b[0m                     )\n\u001b[1;32m     75\u001b[0m                 )\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/audiomentations/augmentations/transforms.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, samples, sample_rate)\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mpitch_shifted_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0msample_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     \u001b[0mn_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_semitones\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m                 )\n\u001b[1;32m    330\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/librosa/effects.py\u001b[0m in \u001b[0;36mpitch_shift\u001b[0;34m(y, sr, n_steps, bins_per_octave, res_type, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0;31m# Stretch in time, then resample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     y_shift = core.resample(\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mtime_stretch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m     )\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mresample\u001b[0;34m(y, orig_sr, target_sr, res_type, fix, scale, **kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamplerate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconverter_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresampy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_sr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_sr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/resampy/core.py\u001b[0m in \u001b[0;36mresample\u001b[0;34m(x, sr_orig, sr_new, axis, filter, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mx_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0my_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0mresample_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterp_win\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterp_delta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_dataset.map(augmented_speech_file_to_array_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'`', '´', 'ʻ', 'ʼ', 'ʽ', '‘', '’'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set('ʻʽʼ‘’´`')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&()*+,./:;<=>?@[\\\\]_{|}~£¤¨©ª«¬®¯°·¸»¼½¾ðʺ˜˝ˮ‐–—―‚“”„‟•…″‽₋€™−√�'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(sorted(set('\\[\\],?.!;:%*½¾¼+=$€£™&©·°\"“”(){}‟ˮ˝ʺ″«»/…‽�–—¨@#¬_•®\\\\₋<>~˜√ð‚¸‐ª¯„−―|¤')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
