{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  '\"sox\" backend is being deprecated. '\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import re\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_code = \"rw\"\n",
    "language = \"kinyarwanda\"\n",
    "model = f\"lucio/wav2vec2-large-xlsr-{language}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.array(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Wav2Vec2ForCTC(\n",
       "  (wav2vec2): Wav2Vec2Model(\n",
       "    (feature_extractor): Wav2Vec2FeatureExtractor(\n",
       "      (conv_layers): ModuleList(\n",
       "        (0): Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (feature_projection): Wav2Vec2FeatureProjection(\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (projection): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      (dropout): Dropout(p=0.05, inplace=False)\n",
       "    )\n",
       "    (encoder): Wav2Vec2EncoderStableLayerNorm(\n",
       "      (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
       "        (conv): Conv1d(1024, 1024, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "        (padding): Wav2Vec2SamePadLayer()\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.05, inplace=False)\n",
       "      (layers): ModuleList(\n",
       "        (0): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.05, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.05, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.05, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.05, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.05, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.05, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.05, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.05, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.05, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.05, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.05, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.05, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.05, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.05, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.05, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.05, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.05, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.05, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.05, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.05, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.05, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.05, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.05, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.05, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (12): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.05, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.05, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (13): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.05, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.05, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (14): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.05, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.05, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (15): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.05, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.05, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (16): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.05, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.05, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (17): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.05, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.05, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (18): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.05, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.05, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (19): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.05, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.05, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (20): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.05, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.05, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (21): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.05, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.05, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (22): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.05, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.05, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (23): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.05, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.05, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (lm_head): Linear(in_features=1024, out_features=28, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(model)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model)\n",
    "model.to(\"cuda\")\n",
    "\n",
    "wer = load_metric(\"wer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Text pre-processing\n",
    "\n",
    "chars_to_ignore_regex = r'[\\[\\],?.!;:*½¼%+=$$€™&©°\"‘’“”(){}‟ˮ‘’´`ʺ″«»<>/…‽�–]'\n",
    "chars_to_ignore_pattern = re.compile(chars_to_ignore_regex)\n",
    "\n",
    "def remove_special_characters(batch):\n",
    "    batch[\"text\"] = re.sub(r'(\\w)[‘’´`](\\w)', r\"\\1'\\2\", batch[\"sentence\"])\n",
    "    batch[\"text\"] = re.sub(chars_to_ignore_regex, \"\", batch[\"text\"]).lower().strip() + \" \"\n",
    "    batch[\"text\"] = re.sub(r\"(-|' | '|  +)\", \" \", batch[\"text\"])\n",
    "    batch[\"text\"] = unidecode.unidecode(batch[\"text\"])\n",
    "    batch[\"length\"] = len(batch[\"text\"])\n",
    "    return batch\n",
    "\n",
    "\n",
    "## Audio pre-processing\n",
    "resampler = torchaudio.transforms.Resample(48_000, 16_000)\n",
    "\n",
    "def speech_file_to_array_fn(batch):\n",
    "    speech_array, sampling_rate = torchaudio.load(batch[\"path\"])\n",
    "    batch[\"speech\"] = resampler(speech_array).squeeze().numpy()\n",
    "    batch[\"sampling_rate\"] = 16_000\n",
    "    return batch\n",
    "\n",
    "\n",
    "# Text transformation and audio resampling\n",
    "def cv_prepare(batch):\n",
    "    batch = remove_special_characters(batch)\n",
    "    batch = speech_file_to_array_fn(batch)\n",
    "\n",
    "    return batch\n",
    "\n",
    "# Number of CPUs or None\n",
    "num_proc = 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset common_voice (/workspace/raw_data/lg/common_voice/lg/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b15463bd11b47df86ed8cda237e9e69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#0', max=146.0, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "764969d09ecf474ea01ab876109f3f4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#2', max=146.0, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a2f688385cd4e8484b8841feaa8f33e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#3', max=146.0, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47dfa011cda74ffcb1fdd014ef425f25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#1', max=146.0, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_dataset = load_dataset(\"common_voice\", lang_code, split=\"test\", cache_dir=f\"/workspace/raw_data/{lang_code}\")\n",
    "\n",
    "test_dataset = test_dataset.map(cv_prepare, num_proc=num_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae075f63fef49d69d45030e5e656b34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=73.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 454.00 MiB (GPU 0; 31.75 GiB total capacity; 1.66 GiB already allocated; 198.50 MiB free; 1.72 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-23a00e5c03fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint)\u001b[0m\n\u001b[1;32m   1425\u001b[0m                 \u001b[0mfn_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1426\u001b[0m                 \u001b[0mnew_fingerprint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_fingerprint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1427\u001b[0;31m                 \u001b[0mupdate_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdate_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1428\u001b[0m             )\n\u001b[1;32m   1429\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m         }\n\u001b[1;32m    202\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;31m# re-apply format to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/fingerprint.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Call actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;31m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_map_single\u001b[0;34m(self, function, with_indices, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, update_data)\u001b[0m\n\u001b[1;32m   1694\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1695\u001b[0m                             batch = apply_function_on_filtered_inputs(\n\u001b[0;32m-> 1696\u001b[0;31m                                 \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_same_num_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1697\u001b[0m                             )\n\u001b[1;32m   1698\u001b[0m                         \u001b[0;32mexcept\u001b[0m \u001b[0mNumExamplesMismatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mapply_function_on_filtered_inputs\u001b[0;34m(inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   1606\u001b[0m                 \u001b[0meffective_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m             processed_inputs = (\n\u001b[0;32m-> 1608\u001b[0;31m                 \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meffective_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mwith_indices\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1609\u001b[0m             )\n\u001b[1;32m   1610\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mupdate_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-130-23a00e5c03fb>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpred_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_values, attention_mask, output_attentions, output_hidden_states, return_dict, labels)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m         )\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_values, attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_values)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mconv_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         return F.layer_norm(\n\u001b[0;32m--> 170\u001b[0;31m             input, self.normalized_shape, self.weight, self.bias, self.eps)\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2093\u001b[0m                 layer_norm, (input,), input, normalized_shape, weight=weight, bias=bias, eps=eps)\n\u001b[1;32m   2094\u001b[0m     return torch.layer_norm(input, normalized_shape, weight, bias, eps,\n\u001b[0;32m-> 2095\u001b[0;31m                             torch.backends.cudnn.enabled)\n\u001b[0m\u001b[1;32m   2096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 454.00 MiB (GPU 0; 31.75 GiB total capacity; 1.66 GiB already allocated; 198.50 MiB free; 1.72 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "def evaluate(batch):\n",
    "    inputs = processor(batch[\"speech\"], sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(inputs.input_values.to(\"cuda\"), attention_mask=inputs.attention_mask.to(\"cuda\")).logits\n",
    "\n",
    "    pred_ids = torch.argmax(logits, dim=-1)\n",
    "    batch[\"pred_strings\"] = processor.batch_decode(pred_ids)\n",
    "    return batch\n",
    "\n",
    "result = test_dataset.map(evaluate, batched=True, batch_size=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('teens', 'male'): 2251,\n",
       "         ('twenties', 'female'): 6235,\n",
       "         ('teens', 'female'): 1755,\n",
       "         ('twenties', 'male'): 3451,\n",
       "         ('twenties', ''): 1340})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(zip(test_dataset['age'], test_dataset['gender']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: 29.805760\n"
     ]
    }
   ],
   "source": [
    "# WER Metric computation\n",
    "\n",
    "import jiwer\n",
    "\n",
    "def chunked_wer(targets, predictions, chunk_size=None):                                          \n",
    "    if chunk_size is None: return jiwer.wer(targets, predictions)                                \n",
    "    start = 0                                                                                    \n",
    "    end = chunk_size                                                                             \n",
    "    H, S, D, I = 0, 0, 0, 0                                                                      \n",
    "    while start < len(targets):                                                                  \n",
    "        chunk_metrics = jiwer.compute_measures(targets[start:end], predictions[start:end])       \n",
    "        H = H + chunk_metrics[\"hits\"]                                                            \n",
    "        S = S + chunk_metrics[\"substitutions\"]                                                   \n",
    "        D = D + chunk_metrics[\"deletions\"]                                                       \n",
    "        I = I + chunk_metrics[\"insertions\"]                                                      \n",
    "        start += chunk_size                                                                      \n",
    "        end += chunk_size                                                                        \n",
    "    return float(S + D + I) / float(H + S + D)\n",
    "\n",
    "print(\"WER: {:2f}\".format(100 * chunked_wer(result[\"sentence\"], result[\"pred_strings\"], chunk_size=4000)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_all_chars(batch):\n",
    "    all_text = \" \".join(batch[\"text\"])\n",
    "    vocab = list(set(all_text))\n",
    "    return {\"vocab\": [vocab], \"all_text\": [all_text]}\n",
    "\n",
    "def strip_accents(batch):\n",
    "   batch[\"sentence\"] = unidecode.unidecode(batch[\"sentence\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset common_voice (/workspace/raw_data/rw/common_voice/rw/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23a90d0136744c3fb1466509d622196f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#2', max=3758.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f766d0cb1f9340c68e033322e83ffe2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#3', max=3758.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95fb3deb1160421e8b6b9224e6234719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#1', max=3758.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c89393da19e8472db402a416e0c77857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#0', max=3758.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "valid_dataset = load_dataset(\"common_voice\", \"rw\", split=\"validation\", cache_dir=\"/workspace/raw_data/rw\")\n",
    "valid_dataset = valid_dataset.map(remove_special_characters, remove_columns=['path'], num_proc=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15032,\n",
       " {'accent': '',\n",
       "  'age': 'teens',\n",
       "  'client_id': '5e85947436bbc805e503bf926beb533b07da07cef77c491a476c8cd1d9bce7b9a4cdc8171564447ea1d2c9c591a203b2e37545a4c8a8f7d0b2881e9e64441e5b',\n",
       "  'down_votes': 1,\n",
       "  'gender': 'male',\n",
       "  'locale': 'rw',\n",
       "  'segment': \"''\",\n",
       "  'sentence': 'Umuntungo we ntabwo aba agomba kuwumarira mu gushakisha imyenda yo kwambara.',\n",
       "  'text': 'umuntungo we ntabwo aba agomba kuwumarira mu gushakisha imyenda yo kwambara ',\n",
       "  'up_votes': 2})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_dataset), valid_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset common_voice (/workspace/raw_data/rw/common_voice/rw/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e71387c598bf469ea384f558d81d9954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#1', max=2576.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca6d3fec3a9a4fcfaed099328d86c3c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#0', max=2576.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fba07c5c78fa486db39a3a82b7c382b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#2', max=2576.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5f4aa203be64bfc8d5bd3318a3fe448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#3', max=2576.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_dataset(\"common_voice\", \"rw\", split=\"train[:2%]\", cache_dir=\"/workspace/raw_data/rw\")\n",
    "train_dataset = train_dataset.map(remove_special_characters, remove_columns=['path'], num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10304,\n",
       " {'accent': '',\n",
       "  'age': 'twenties',\n",
       "  'client_id': 'd4439c64c8f13b84cd2ce31d5d9eeae2a81147d89abb00cebaaf11b60b7166c24dd257a44e73c72c73c93cae29d904bed135824aca06e5970e001e9406e8a891',\n",
       "  'down_votes': 1,\n",
       "  'gender': 'male',\n",
       "  'length': 53,\n",
       "  'locale': 'rw',\n",
       "  'segment': \"''\",\n",
       "  'sentence': 'akunda u rwanda cyane cyane ku byerekeye isuku ihaba',\n",
       "  'text': 'akunda u rwanda cyane cyane ku byerekeye isuku ihaba ',\n",
       "  'up_votes': 2},\n",
       " [53,\n",
       "  58,\n",
       "  44,\n",
       "  37,\n",
       "  164,\n",
       "  38,\n",
       "  48,\n",
       "  36,\n",
       "  37,\n",
       "  49,\n",
       "  44,\n",
       "  41,\n",
       "  21,\n",
       "  47,\n",
       "  24,\n",
       "  54,\n",
       "  28,\n",
       "  78,\n",
       "  45,\n",
       "  24,\n",
       "  42,\n",
       "  48,\n",
       "  36,\n",
       "  47,\n",
       "  56,\n",
       "  54,\n",
       "  71,\n",
       "  24,\n",
       "  27,\n",
       "  28,\n",
       "  51,\n",
       "  34,\n",
       "  39,\n",
       "  63,\n",
       "  46,\n",
       "  29,\n",
       "  83,\n",
       "  38,\n",
       "  47,\n",
       "  84,\n",
       "  32,\n",
       "  85,\n",
       "  41,\n",
       "  38,\n",
       "  25,\n",
       "  38,\n",
       "  37,\n",
       "  62,\n",
       "  94,\n",
       "  56,\n",
       "  34,\n",
       "  37,\n",
       "  103,\n",
       "  66,\n",
       "  33,\n",
       "  47,\n",
       "  79,\n",
       "  39,\n",
       "  30,\n",
       "  26,\n",
       "  44,\n",
       "  80,\n",
       "  35,\n",
       "  49,\n",
       "  36,\n",
       "  50,\n",
       "  40,\n",
       "  46,\n",
       "  42,\n",
       "  32,\n",
       "  64,\n",
       "  48,\n",
       "  76,\n",
       "  49,\n",
       "  41,\n",
       "  40,\n",
       "  36,\n",
       "  57,\n",
       "  37,\n",
       "  38,\n",
       "  32,\n",
       "  26,\n",
       "  19,\n",
       "  46,\n",
       "  29,\n",
       "  46,\n",
       "  33,\n",
       "  42,\n",
       "  51,\n",
       "  36,\n",
       "  42,\n",
       "  44,\n",
       "  42,\n",
       "  42,\n",
       "  59,\n",
       "  17,\n",
       "  51,\n",
       "  50,\n",
       "  51,\n",
       "  40,\n",
       "  71,\n",
       "  44,\n",
       "  30,\n",
       "  44,\n",
       "  30,\n",
       "  44,\n",
       "  59,\n",
       "  38,\n",
       "  95,\n",
       "  56,\n",
       "  48,\n",
       "  24,\n",
       "  29,\n",
       "  42,\n",
       "  53,\n",
       "  20,\n",
       "  41,\n",
       "  32,\n",
       "  33,\n",
       "  36,\n",
       "  35,\n",
       "  38,\n",
       "  39,\n",
       "  26,\n",
       "  34,\n",
       "  51,\n",
       "  36,\n",
       "  45,\n",
       "  48,\n",
       "  42,\n",
       "  58,\n",
       "  57,\n",
       "  41,\n",
       "  26,\n",
       "  43,\n",
       "  43,\n",
       "  40,\n",
       "  34,\n",
       "  41,\n",
       "  38,\n",
       "  30,\n",
       "  42,\n",
       "  27,\n",
       "  37,\n",
       "  35,\n",
       "  43,\n",
       "  42,\n",
       "  34,\n",
       "  46,\n",
       "  45,\n",
       "  46,\n",
       "  26,\n",
       "  49,\n",
       "  22,\n",
       "  33,\n",
       "  26,\n",
       "  47,\n",
       "  46,\n",
       "  31,\n",
       "  36,\n",
       "  33,\n",
       "  19,\n",
       "  29,\n",
       "  25,\n",
       "  49,\n",
       "  53,\n",
       "  49,\n",
       "  30,\n",
       "  45,\n",
       "  42,\n",
       "  28,\n",
       "  34,\n",
       "  24,\n",
       "  40,\n",
       "  32,\n",
       "  33,\n",
       "  46,\n",
       "  27,\n",
       "  25,\n",
       "  29,\n",
       "  28,\n",
       "  43,\n",
       "  40,\n",
       "  22,\n",
       "  34,\n",
       "  36,\n",
       "  45,\n",
       "  33,\n",
       "  30,\n",
       "  41,\n",
       "  32,\n",
       "  42,\n",
       "  30,\n",
       "  37,\n",
       "  23,\n",
       "  67,\n",
       "  74,\n",
       "  50,\n",
       "  47,\n",
       "  45,\n",
       "  25,\n",
       "  95,\n",
       "  31,\n",
       "  24,\n",
       "  26,\n",
       "  33,\n",
       "  37,\n",
       "  51,\n",
       "  55,\n",
       "  45,\n",
       "  58,\n",
       "  54,\n",
       "  32,\n",
       "  39,\n",
       "  30,\n",
       "  55,\n",
       "  32,\n",
       "  34,\n",
       "  25,\n",
       "  37,\n",
       "  48,\n",
       "  44,\n",
       "  30,\n",
       "  49,\n",
       "  31,\n",
       "  62,\n",
       "  51,\n",
       "  55,\n",
       "  42,\n",
       "  47,\n",
       "  32,\n",
       "  37,\n",
       "  31,\n",
       "  56,\n",
       "  39,\n",
       "  31,\n",
       "  46,\n",
       "  39,\n",
       "  70,\n",
       "  53,\n",
       "  37,\n",
       "  38,\n",
       "  34,\n",
       "  42,\n",
       "  48,\n",
       "  27,\n",
       "  43,\n",
       "  35,\n",
       "  29,\n",
       "  24,\n",
       "  42,\n",
       "  41,\n",
       "  26,\n",
       "  28,\n",
       "  27,\n",
       "  23,\n",
       "  33,\n",
       "  40,\n",
       "  47,\n",
       "  42,\n",
       "  31,\n",
       "  41,\n",
       "  47,\n",
       "  41,\n",
       "  44,\n",
       "  19,\n",
       "  58,\n",
       "  40,\n",
       "  49,\n",
       "  36,\n",
       "  61,\n",
       "  41,\n",
       "  49,\n",
       "  53,\n",
       "  39,\n",
       "  40,\n",
       "  28,\n",
       "  40,\n",
       "  18,\n",
       "  40,\n",
       "  41,\n",
       "  32,\n",
       "  43,\n",
       "  25,\n",
       "  58,\n",
       "  61,\n",
       "  39,\n",
       "  31,\n",
       "  44,\n",
       "  50,\n",
       "  27,\n",
       "  48,\n",
       "  37,\n",
       "  71,\n",
       "  61,\n",
       "  39,\n",
       "  31,\n",
       "  60,\n",
       "  38,\n",
       "  44,\n",
       "  35,\n",
       "  23,\n",
       "  48,\n",
       "  38,\n",
       "  66,\n",
       "  42,\n",
       "  29,\n",
       "  44,\n",
       "  39,\n",
       "  28,\n",
       "  26,\n",
       "  39,\n",
       "  32,\n",
       "  37,\n",
       "  64,\n",
       "  39,\n",
       "  44,\n",
       "  44,\n",
       "  40,\n",
       "  43,\n",
       "  41,\n",
       "  45,\n",
       "  33,\n",
       "  45,\n",
       "  50,\n",
       "  23,\n",
       "  47,\n",
       "  41,\n",
       "  31,\n",
       "  34,\n",
       "  47,\n",
       "  42,\n",
       "  32,\n",
       "  31,\n",
       "  28,\n",
       "  32,\n",
       "  32,\n",
       "  30,\n",
       "  41,\n",
       "  24,\n",
       "  42,\n",
       "  42,\n",
       "  31,\n",
       "  58,\n",
       "  44,\n",
       "  32,\n",
       "  26,\n",
       "  45,\n",
       "  25,\n",
       "  56,\n",
       "  48,\n",
       "  50,\n",
       "  31,\n",
       "  52,\n",
       "  39,\n",
       "  35,\n",
       "  22,\n",
       "  58,\n",
       "  31,\n",
       "  46,\n",
       "  29,\n",
       "  51,\n",
       "  47,\n",
       "  18,\n",
       "  23,\n",
       "  26,\n",
       "  50,\n",
       "  32,\n",
       "  27,\n",
       "  49,\n",
       "  37,\n",
       "  36,\n",
       "  47,\n",
       "  30,\n",
       "  45,\n",
       "  25,\n",
       "  44,\n",
       "  41,\n",
       "  32,\n",
       "  41,\n",
       "  32,\n",
       "  34,\n",
       "  32,\n",
       "  20,\n",
       "  22,\n",
       "  33,\n",
       "  36,\n",
       "  34,\n",
       "  33,\n",
       "  40,\n",
       "  35,\n",
       "  48,\n",
       "  23,\n",
       "  44,\n",
       "  39,\n",
       "  42,\n",
       "  42,\n",
       "  67,\n",
       "  42,\n",
       "  39,\n",
       "  39,\n",
       "  41,\n",
       "  40,\n",
       "  32,\n",
       "  19,\n",
       "  41,\n",
       "  77,\n",
       "  22,\n",
       "  48,\n",
       "  42,\n",
       "  35,\n",
       "  39,\n",
       "  39,\n",
       "  35,\n",
       "  67,\n",
       "  29,\n",
       "  40,\n",
       "  51,\n",
       "  47,\n",
       "  45,\n",
       "  37,\n",
       "  25,\n",
       "  41,\n",
       "  28,\n",
       "  32,\n",
       "  64,\n",
       "  35,\n",
       "  79,\n",
       "  35,\n",
       "  45,\n",
       "  37,\n",
       "  37,\n",
       "  40,\n",
       "  21,\n",
       "  30,\n",
       "  30,\n",
       "  29,\n",
       "  36,\n",
       "  41,\n",
       "  28,\n",
       "  26,\n",
       "  40,\n",
       "  45,\n",
       "  39,\n",
       "  46,\n",
       "  37,\n",
       "  58,\n",
       "  59,\n",
       "  42,\n",
       "  24,\n",
       "  37,\n",
       "  34,\n",
       "  40,\n",
       "  36,\n",
       "  55,\n",
       "  46,\n",
       "  41,\n",
       "  31,\n",
       "  46,\n",
       "  43,\n",
       "  34,\n",
       "  31,\n",
       "  30,\n",
       "  53,\n",
       "  52,\n",
       "  27,\n",
       "  39,\n",
       "  41,\n",
       "  48,\n",
       "  28,\n",
       "  36,\n",
       "  42,\n",
       "  49,\n",
       "  45,\n",
       "  29,\n",
       "  40,\n",
       "  30,\n",
       "  24,\n",
       "  26,\n",
       "  50,\n",
       "  27,\n",
       "  31,\n",
       "  26,\n",
       "  50,\n",
       "  31,\n",
       "  32,\n",
       "  57,\n",
       "  60,\n",
       "  44,\n",
       "  58,\n",
       "  42,\n",
       "  44,\n",
       "  49,\n",
       "  39,\n",
       "  35,\n",
       "  77,\n",
       "  36,\n",
       "  38,\n",
       "  24,\n",
       "  33,\n",
       "  58,\n",
       "  60,\n",
       "  43,\n",
       "  71,\n",
       "  71,\n",
       "  42,\n",
       "  36,\n",
       "  40,\n",
       "  58,\n",
       "  45,\n",
       "  46,\n",
       "  31,\n",
       "  47,\n",
       "  33,\n",
       "  45,\n",
       "  36,\n",
       "  39,\n",
       "  50,\n",
       "  23,\n",
       "  45,\n",
       "  55,\n",
       "  40,\n",
       "  59,\n",
       "  40,\n",
       "  41,\n",
       "  34,\n",
       "  46,\n",
       "  61,\n",
       "  38,\n",
       "  33,\n",
       "  40,\n",
       "  52,\n",
       "  45,\n",
       "  53,\n",
       "  40,\n",
       "  37,\n",
       "  40,\n",
       "  29,\n",
       "  22,\n",
       "  29,\n",
       "  39,\n",
       "  42,\n",
       "  38,\n",
       "  32,\n",
       "  31,\n",
       "  34,\n",
       "  46,\n",
       "  65,\n",
       "  31,\n",
       "  61,\n",
       "  38,\n",
       "  25,\n",
       "  30,\n",
       "  39,\n",
       "  31,\n",
       "  29,\n",
       "  36,\n",
       "  29,\n",
       "  45,\n",
       "  36,\n",
       "  39,\n",
       "  32,\n",
       "  41,\n",
       "  49,\n",
       "  48,\n",
       "  32,\n",
       "  40,\n",
       "  51,\n",
       "  34,\n",
       "  30,\n",
       "  49,\n",
       "  50,\n",
       "  49,\n",
       "  48,\n",
       "  25,\n",
       "  49,\n",
       "  29,\n",
       "  33,\n",
       "  35,\n",
       "  38,\n",
       "  38,\n",
       "  46,\n",
       "  30,\n",
       "  46,\n",
       "  29,\n",
       "  33,\n",
       "  52,\n",
       "  46,\n",
       "  48,\n",
       "  35,\n",
       "  28,\n",
       "  33,\n",
       "  48,\n",
       "  55,\n",
       "  48,\n",
       "  29,\n",
       "  46,\n",
       "  46,\n",
       "  34,\n",
       "  26,\n",
       "  28,\n",
       "  42,\n",
       "  39,\n",
       "  39,\n",
       "  44,\n",
       "  24,\n",
       "  50,\n",
       "  43,\n",
       "  30,\n",
       "  43,\n",
       "  48,\n",
       "  41,\n",
       "  42,\n",
       "  27,\n",
       "  75,\n",
       "  26,\n",
       "  37,\n",
       "  35,\n",
       "  28,\n",
       "  28,\n",
       "  43,\n",
       "  27,\n",
       "  37,\n",
       "  42,\n",
       "  49,\n",
       "  33,\n",
       "  27,\n",
       "  30,\n",
       "  51,\n",
       "  44,\n",
       "  25,\n",
       "  38,\n",
       "  21,\n",
       "  36,\n",
       "  37,\n",
       "  35,\n",
       "  32,\n",
       "  27,\n",
       "  36,\n",
       "  53,\n",
       "  45,\n",
       "  30,\n",
       "  45,\n",
       "  33,\n",
       "  28,\n",
       "  37,\n",
       "  37,\n",
       "  46,\n",
       "  43,\n",
       "  38,\n",
       "  44,\n",
       "  33,\n",
       "  36,\n",
       "  47,\n",
       "  46,\n",
       "  39,\n",
       "  38,\n",
       "  40,\n",
       "  38,\n",
       "  22,\n",
       "  43,\n",
       "  31,\n",
       "  35,\n",
       "  25,\n",
       "  36,\n",
       "  23,\n",
       "  46,\n",
       "  46,\n",
       "  37,\n",
       "  45,\n",
       "  34,\n",
       "  49,\n",
       "  43,\n",
       "  45,\n",
       "  28,\n",
       "  24,\n",
       "  33,\n",
       "  40,\n",
       "  75,\n",
       "  27,\n",
       "  45,\n",
       "  31,\n",
       "  41,\n",
       "  38,\n",
       "  25,\n",
       "  31,\n",
       "  33,\n",
       "  37,\n",
       "  40,\n",
       "  51,\n",
       "  35,\n",
       "  39,\n",
       "  42,\n",
       "  54,\n",
       "  43,\n",
       "  30,\n",
       "  36,\n",
       "  43,\n",
       "  41,\n",
       "  45,\n",
       "  44,\n",
       "  37,\n",
       "  27,\n",
       "  30,\n",
       "  42,\n",
       "  43,\n",
       "  58,\n",
       "  40,\n",
       "  38,\n",
       "  31,\n",
       "  51,\n",
       "  40,\n",
       "  34,\n",
       "  35,\n",
       "  44,\n",
       "  41,\n",
       "  17,\n",
       "  35,\n",
       "  25,\n",
       "  69,\n",
       "  59,\n",
       "  42,\n",
       "  27,\n",
       "  29,\n",
       "  47,\n",
       "  39,\n",
       "  35,\n",
       "  26,\n",
       "  47,\n",
       "  29,\n",
       "  54,\n",
       "  28,\n",
       "  45,\n",
       "  44,\n",
       "  49,\n",
       "  56,\n",
       "  59,\n",
       "  43,\n",
       "  28,\n",
       "  36,\n",
       "  50,\n",
       "  38,\n",
       "  33,\n",
       "  27,\n",
       "  40,\n",
       "  25,\n",
       "  40,\n",
       "  37,\n",
       "  24,\n",
       "  49,\n",
       "  35,\n",
       "  38,\n",
       "  39,\n",
       "  31,\n",
       "  56,\n",
       "  48,\n",
       "  38,\n",
       "  56,\n",
       "  32,\n",
       "  75,\n",
       "  53,\n",
       "  44,\n",
       "  34,\n",
       "  50,\n",
       "  34,\n",
       "  53,\n",
       "  45,\n",
       "  40,\n",
       "  37,\n",
       "  49,\n",
       "  44,\n",
       "  50,\n",
       "  54,\n",
       "  34,\n",
       "  53,\n",
       "  53,\n",
       "  41,\n",
       "  35,\n",
       "  42,\n",
       "  39,\n",
       "  45,\n",
       "  42,\n",
       "  51,\n",
       "  33,\n",
       "  43,\n",
       "  84,\n",
       "  45,\n",
       "  28,\n",
       "  34,\n",
       "  30,\n",
       "  43,\n",
       "  33,\n",
       "  52,\n",
       "  66,\n",
       "  41,\n",
       "  35,\n",
       "  71,\n",
       "  27,\n",
       "  44,\n",
       "  27,\n",
       "  28,\n",
       "  46,\n",
       "  52,\n",
       "  50,\n",
       "  41,\n",
       "  35,\n",
       "  41,\n",
       "  40,\n",
       "  33,\n",
       "  38,\n",
       "  33,\n",
       "  43,\n",
       "  34,\n",
       "  47,\n",
       "  48,\n",
       "  40,\n",
       "  72,\n",
       "  63,\n",
       "  14,\n",
       "  51,\n",
       "  16,\n",
       "  62,\n",
       "  49,\n",
       "  36,\n",
       "  43,\n",
       "  31,\n",
       "  38,\n",
       "  72,\n",
       "  45,\n",
       "  32,\n",
       "  25,\n",
       "  40,\n",
       "  45,\n",
       "  38,\n",
       "  29,\n",
       "  37,\n",
       "  40,\n",
       "  40,\n",
       "  37,\n",
       "  44,\n",
       "  41,\n",
       "  47,\n",
       "  53,\n",
       "  44,\n",
       "  46,\n",
       "  31,\n",
       "  37,\n",
       "  43,\n",
       "  36,\n",
       "  23,\n",
       "  47,\n",
       "  43,\n",
       "  20,\n",
       "  48,\n",
       "  35,\n",
       "  49,\n",
       "  35,\n",
       "  44,\n",
       "  39,\n",
       "  31,\n",
       "  46,\n",
       "  35,\n",
       "  41,\n",
       "  42,\n",
       "  51,\n",
       "  26,\n",
       "  35,\n",
       "  28,\n",
       "  26,\n",
       "  43,\n",
       "  39,\n",
       "  32,\n",
       "  51,\n",
       "  38,\n",
       "  27,\n",
       "  46,\n",
       "  45,\n",
       "  21,\n",
       "  41,\n",
       "  56,\n",
       "  48,\n",
       "  33,\n",
       "  35,\n",
       "  36,\n",
       "  43,\n",
       "  45,\n",
       "  52,\n",
       "  67,\n",
       "  54,\n",
       "  45,\n",
       "  29,\n",
       "  48,\n",
       "  41,\n",
       "  51,\n",
       "  36,\n",
       "  35,\n",
       "  41,\n",
       "  37,\n",
       "  37,\n",
       "  41,\n",
       "  36,\n",
       "  43,\n",
       "  51,\n",
       "  61,\n",
       "  59,\n",
       "  33,\n",
       "  56,\n",
       "  20,\n",
       "  46,\n",
       "  40,\n",
       "  44,\n",
       "  43,\n",
       "  52,\n",
       "  39,\n",
       "  40,\n",
       "  42,\n",
       "  55,\n",
       "  61,\n",
       "  51,\n",
       "  47,\n",
       "  57,\n",
       "  34,\n",
       "  25,\n",
       "  33,\n",
       "  39,\n",
       "  44,\n",
       "  29,\n",
       "  26,\n",
       "  35,\n",
       "  41,\n",
       "  35,\n",
       "  36,\n",
       "  35,\n",
       "  30,\n",
       "  40,\n",
       "  30,\n",
       "  43,\n",
       "  37,\n",
       "  61,\n",
       "  33,\n",
       "  47,\n",
       "  43,\n",
       "  24,\n",
       "  45,\n",
       "  23,\n",
       "  87,\n",
       "  45,\n",
       "  46,\n",
       "  42,\n",
       "  36,\n",
       "  37,\n",
       "  39,\n",
       "  60,\n",
       "  44,\n",
       "  47,\n",
       "  41,\n",
       "  39,\n",
       "  63,\n",
       "  35,\n",
       "  41,\n",
       "  39,\n",
       "  45,\n",
       "  45,\n",
       "  37,\n",
       "  63,\n",
       "  34,\n",
       "  47,\n",
       "  32,\n",
       "  46,\n",
       "  38,\n",
       "  38,\n",
       "  39,\n",
       "  69,\n",
       "  51,\n",
       "  41,\n",
       "  63,\n",
       "  40,\n",
       "  49,\n",
       "  49,\n",
       "  38,\n",
       "  70,\n",
       "  35,\n",
       "  45,\n",
       "  39,\n",
       "  35,\n",
       "  40,\n",
       "  42,\n",
       "  43,\n",
       "  39,\n",
       "  46,\n",
       "  40,\n",
       "  28,\n",
       "  57,\n",
       "  68,\n",
       "  46,\n",
       "  46,\n",
       "  44,\n",
       "  26,\n",
       "  26,\n",
       "  41,\n",
       "  ...])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), train_dataset[0], train_dataset[\"length\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('teens', 'male'): 2251,\n",
       "         ('twenties', 'female'): 6235,\n",
       "         ('teens', 'female'): 1755,\n",
       "         ('twenties', 'male'): 3451,\n",
       "         ('twenties', ''): 1340})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter \n",
    "\n",
    "Counter(zip(valid_dataset['age'], valid_dataset['gender']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('twenties', 'male'): 16411,\n",
       "         ('teens', 'female'): 12038,\n",
       "         ('thirties', 'male'): 5512,\n",
       "         ('twenties', ''): 5628,\n",
       "         ('thirties', 'female'): 2134,\n",
       "         ('twenties', 'female'): 6273,\n",
       "         ('teens', 'male'): 3524})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(zip(train_dataset['age'], train_dataset['gender']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c6c298e7934eab8b41b625d2b21eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vocab = valid_dataset.map(\n",
    "    extract_all_chars,\n",
    "    batched=True,\n",
    "    batch_size=-1,\n",
    "    keep_in_memory=True,\n",
    "    remove_columns=valid_dataset.column_names,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-1f8b23a1e3a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m vocab_test = test_dataset.map(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mextract_all_chars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mkeep_in_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "vocab_test = test_dataset.map(\n",
    "    extract_all_chars,\n",
    "    batched=True,\n",
    "    batch_size=-1,\n",
    "    keep_in_memory=True,\n",
    "    remove_columns=test_dataset.column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'u': 66225,\n",
       "         'm': 36247,\n",
       "         'n': 52029,\n",
       "         't': 22892,\n",
       "         'g': 29882,\n",
       "         'o': 40150,\n",
       "         ' ': 146733,\n",
       "         'w': 22352,\n",
       "         'e': 52965,\n",
       "         'a': 134320,\n",
       "         'b': 46183,\n",
       "         'k': 36256,\n",
       "         'r': 47648,\n",
       "         'i': 84230,\n",
       "         's': 19735,\n",
       "         'h': 20429,\n",
       "         'y': 35120,\n",
       "         'd': 11235,\n",
       "         'c': 6360,\n",
       "         'l': 3378,\n",
       "         \"'\": 7024,\n",
       "         'z': 17673,\n",
       "         'j': 4789,\n",
       "         'f': 4162,\n",
       "         'v': 3791,\n",
       "         'p': 3312,\n",
       "         'x': 67,\n",
       "         'q': 72})"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "cnts = Counter(vocab[0]['all_text'])\n",
    "cnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('x', 67), ('q', 72), ('<', 60), ('>', 30), ('$', 3), ('4', 2), ('+', 1)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unidecode\n",
    "[(unidecode.unidecode(k), cnts[k]) for k in cnts if cnts[k] < 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Umuntungo we ntabwo aba agomba kuwumarira mu gushakisha imyenda yo kwambara.',\n",
       "  'umuntungo we ntabwo aba agomba kuwumarira mu gushakisha imyenda yo kwambara '),\n",
       " ('Richard Gordon Turnbull ko atemeranya n’abashobora gukandamiza abandi bitwaje ibara ry’uruhu.',\n",
       "  \"richard gordon turnbull ko atemeranya n'abashobora gukandamiza abandi bitwaje ibara ry'uruhu \"),\n",
       " ('Ni inka ikurikiranwa hifashishijwe ikoranabuhanga, buri uko yabira biba bisuzumwa.',\n",
       "  'ni inka ikurikiranwa hifashishijwe ikoranabuhanga buri uko yabira biba bisuzumwa '),\n",
       " ('Ati, “Benshi bafatwa baba ari urubyiruko, hari ababa banyoye ibiyobyabwenge.',\n",
       "  'ati benshi bafatwa baba ari urubyiruko hari ababa banyoye ibiyobyabwenge '),\n",
       " ('Olivis : Inzozi ze ni uguhura na Producer ukomeye muri Amerika “Timberland” akabakorera indirimbo.',\n",
       "  'olivis inzozi ze ni uguhura na producer ukomeye muri amerika timberland akabakorera indirimbo '),\n",
       " ('ibitaramo bitandukanye mu Rwanda avuga ko yari abikumbuye ariko ngo byamubereye.',\n",
       "  'ibitaramo bitandukanye mu rwanda avuga ko yari abikumbuye ariko ngo byamubereye '),\n",
       " ('Hanyuma hepfo byasaba gusinya kuko n’izina babaga bariteguye bihagije ari isinya isigaye gusa.',\n",
       "  \"hanyuma hepfo byasaba gusinya kuko n'izina babaga bariteguye bihagije ari isinya isigaye gusa \"),\n",
       " ('Amashirahamwe aharanira agateka ka zina muntu yanebaguye iyo ngingo yo gukubita abo bapfasoni.',\n",
       "  'amashirahamwe aharanira agateka ka zina muntu yanebaguye iyo ngingo yo gukubita abo bapfasoni '),\n",
       " ('Abo imvura yasenyerye amazu ubu bacumbikiwe n’abatesenyewe.',\n",
       "  \"abo imvura yasenyerye amazu ubu bacumbikiwe n'abatesenyewe \"),\n",
       " ('Icyo basabwa gusa ni ikarita y’ubwisungane mu kwivuza ariyo Mitiweri.',\n",
       "  \"icyo basabwa gusa ni ikarita y'ubwisungane mu kwivuza ariyo mitiweri \"),\n",
       " ('Hateganyijwe kuzashyiraho urwego rw’ubugenzuzi buzakurikirana iyubahirizwa ry’iri tegeko.',\n",
       "  \"hateganyijwe kuzashyiraho urwego rw'ubugenzuzi buzakurikirana iyubahirizwa ry'iri tegeko \"),\n",
       " ('Ariko Iyo ugeze mu Rwanda usanga abanyarwanda tugerageza kuganira neza abacongomani.',\n",
       "  'ariko iyo ugeze mu rwanda usanga abanyarwanda tugerageza kuganira neza abacongomani '),\n",
       " ('Ni umwe mu batangiye kuri radiyo bahembwa agatubutse.',\n",
       "  'ni umwe mu batangiye kuri radiyo bahembwa agatubutse '),\n",
       " ('Yagize ati ‘Ntiyigeze asaba imbabazi nyuma yo gusambanya umugore wa murumuna we Rhodri.',\n",
       "  'yagize ati ntiyigeze asaba imbabazi nyuma yo gusambanya umugore wa murumuna we rhodri '),\n",
       " ('Nukuvuga ko iyo Komisiyo y’Amatora yagombye gukurikirana abantu bavuga ko basinyishije abapfuye.',\n",
       "  \"nukuvuga ko iyo komisiyo y'amatora yagombye gukurikirana abantu bavuga ko basinyishije abapfuye \"),\n",
       " ('Numvaga nshaka gupfa kuko siniyumvishaga ko hari ikiremwamuntu cyakwihanganira uburibwe nari mfite.',\n",
       "  'numvaga nshaka gupfa kuko siniyumvishaga ko hari ikiremwamuntu cyakwihanganira uburibwe nari mfite '),\n",
       " ('Akomeza avuga ko batatu muri bo batawe muri yombi usibye Rudomoro.',\n",
       "  'akomeza avuga ko batatu muri bo batawe muri yombi usibye rudomoro '),\n",
       " ('Naho isuku yariyongereye, ubu ni umuhanda w’icyitegererezo.',\n",
       "  \"naho isuku yariyongereye ubu ni umuhanda w'icyitegererezo \"),\n",
       " ('Abaye umwami uganje, utagira undi barwanira intebe y’ubwami.',\n",
       "  \"abaye umwami uganje utagira undi barwanira intebe y'ubwami \"),\n",
       " ('Aho Perezida Kagame arara mu mahoteli ahenze kurusha abaprezida bamuha inkunga.',\n",
       "  'aho perezida kagame arara mu mahoteli ahenze kurusha abaprezida bamuha inkunga '),\n",
       " ('Yakomeje ati “Muvandimwe Paul Kagame, tunejejwe no kuba wabibashije.',\n",
       "  'yakomeje ati muvandimwe paul kagame tunejejwe no kuba wabibashije '),\n",
       " ('ariko nkibariza wa mukobwa we,ubwo urakomeje cyangwa urikinira?.',\n",
       "  'ariko nkibariza wa mukobwa weubwo urakomeje cyangwa urikinira '),\n",
       " ('uburezi murwanda bugeze kure', 'uburezi murwanda bugeze kure '),\n",
       " ('Kim Jong-nam, ntiyavuga neza intwaro ya Korea ya ruguru.',\n",
       "  'kim jong nam ntiyavuga neza intwaro ya korea ya ruguru '),\n",
       " ('hazaba hahatana inde na nde se?', 'hazaba hahatana inde na nde se '),\n",
       " ('Kuvuga ko gukora imibonano cyane byangiza igitsina.',\n",
       "  'kuvuga ko gukora imibonano cyane byangiza igitsina '),\n",
       " ('Agira ati ”Turakuriza amikoro y’igihugu, ariko turi kumwe n’abafatanyabikorwa.',\n",
       "  \"agira ati turakuriza amikoro y'igihugu ariko turi kumwe n'abafatanyabikorwa \"),\n",
       " ('Miss Jolly nawe ari mu bitabiriye iyi gahunda.',\n",
       "  'miss jolly nawe ari mu bitabiriye iyi gahunda '),\n",
       " ('com ko yumva afite amatsiko yo kubona abantu bateranye batashye ubukwe.',\n",
       "  'com ko yumva afite amatsiko yo kubona abantu bateranye batashye ubukwe '),\n",
       " ('Umwanditsi ni umunyeshuri mu mategeko muri kaminuza.',\n",
       "  'umwanditsi ni umunyeshuri mu mategeko muri kaminuza '),\n",
       " ('Icyo gihe abantu batandukanye barabinenze bavuga ko ari ugutesha agaciro ba Nyampinga.',\n",
       "  'icyo gihe abantu batandukanye barabinenze bavuga ko ari ugutesha agaciro ba nyampinga '),\n",
       " ('James Gondolfini, umukinnyi wa film w’umunyamerika nibwo yavutse aza kwitaba Imana mu .',\n",
       "  \"james gondolfini umukinnyi wa film w'umunyamerika nibwo yavutse aza kwitaba imana mu \"),\n",
       " ('Umwuga wamuhesheje ubushobozi bwo kugura telefone, mudasobwa nziza, imodoka n’inzu yo kubamo.',\n",
       "  \"umwuga wamuhesheje ubushobozi bwo kugura telefone mudasobwa nziza imodoka n'inzu yo kubamo \"),\n",
       " ('Ubu harimo kugenzurwa abujuje ibyangombwa hakurikijwe Iteka rya Minisitiri kandi vuba aha biraba birangiye.”',\n",
       "  'ubu harimo kugenzurwa abujuje ibyangombwa hakurikijwe iteka rya minisitiri kandi vuba aha biraba birangiye '),\n",
       " ('Ibiziga vy’abantu birenga mirongo ibiri birambaraye mu kibanza cabereyemwo iyo mpanuka.',\n",
       "  \"ibiziga vy'abantu birenga mirongo ibiri birambaraye mu kibanza cabereyemwo iyo mpanuka \"),\n",
       " ('Ubu meze neza kurusha uko byari bimeze mu myaka ine ishize.',\n",
       "  'ubu meze neza kurusha uko byari bimeze mu myaka ine ishize '),\n",
       " ('Turateganya gukomeza kubegera tukabaganiriza tukabafasha kwibumbira mu mashyirahamwe”.',\n",
       "  'turateganya gukomeza kubegera tukabaganiriza tukabafasha kwibumbira mu mashyirahamwe '),\n",
       " ('Me Gatera Gashabana yavuze ko ibiganiro by’ubuzima bwite ubushinjacyaha bushingiraho bikwiye guteshwa agaciro.',\n",
       "  \"me gatera gashabana yavuze ko ibiganiro by'ubuzima bwite ubushinjacyaha bushingiraho bikwiye guteshwa agaciro \"),\n",
       " ('Uriya Musaza yicishaga bugufi cyane akagira neza bose.',\n",
       "  'uriya musaza yicishaga bugufi cyane akagira neza bose '),\n",
       " ('Kwizera Pierre Marchal asezera ku bakunzi ba Volleyball.',\n",
       "  'kwizera pierre marchal asezera ku bakunzi ba volleyball '),\n",
       " ('Ati “Ndabashimira ko mwitabira Umuganda mwese: abasore, inkumi, urubyiruko n’abakuru.',\n",
       "  \"ati ndabashimira ko mwitabira umuganda mwese abasore inkumi urubyiruko n'abakuru \"),\n",
       " ('Mukakayibanda Alphonsine ni umwe mubasigajwe inyuma n’amateka wo mu murenge wa Bushenge.',\n",
       "  \"mukakayibanda alphonsine ni umwe mubasigajwe inyuma n'amateka wo mu murenge wa bushenge \"),\n",
       " ('La Jeunesse mu isura nshya “Iga Kina Tsinda” .',\n",
       "  'la jeunesse mu isura nshya iga kina tsinda '),\n",
       " ('Nenze kwimanika agahinda karanyishe mbura uko mbigira ndumirwa.',\n",
       "  'nenze kwimanika agahinda karanyishe mbura uko mbigira ndumirwa '),\n",
       " ('Uwumuremyi Vitar kugira ngo azashinje Ingabire Victaoire.',\n",
       "  'uwumuremyi vitar kugira ngo azashinje ingabire victaoire '),\n",
       " ('Byarangira uyoboye icyamunara ati ‘aragurishijwe.',\n",
       "  'byarangira uyoboye icyamunara ati aragurishijwe '),\n",
       " ('Ati “ Ndabizi ko izi ngeso zitemewe k’umuntu nkanjye ukinira ikipe y’igihugu.',\n",
       "  \"ati ndabizi ko izi ngeso zitemewe k'umuntu nkanjye ukinira ikipe y'igihugu \"),\n",
       " ('Ejo bavugaga ngo ntabwo bazabyemera kandi kongere bucya ngo itangire !',\n",
       "  'ejo bavugaga ngo ntabwo bazabyemera kandi kongere bucya ngo itangire '),\n",
       " ('Ubucukuzi bw’amabuye y’agaciro bukorerwa cyane mu Mirenge ya Rukoma, Ngamba na Kayenzi.',\n",
       "  \"ubucukuzi bw'amabuye y'agaciro bukorerwa cyane mu mirenge ya rukoma ngamba na kayenzi \"),\n",
       " ('\"Bagiye kumurika album yabo ya mbere \\'Ishimwe ni iryawe\\'.\"',\n",
       "  'bagiye kumurika album yabo ya mbere ishimwe ni iryawe '),\n",
       " ('Singombwa rero kugira ubwoba ngo uhagarike ingendo ngaho ngo uri gutinya impanuka.',\n",
       "  'singombwa rero kugira ubwoba ngo uhagarike ingendo ngaho ngo uri gutinya impanuka '),\n",
       " ('\"Ibi bishyimbo ngo bifite intungamubiri utasanga mu yandi moko y\\'ibishyimbo.\"',\n",
       "  \"ibi bishyimbo ngo bifite intungamubiri utasanga mu yandi moko y'ibishyimbo \"),\n",
       " ('Berita yanyuzwe no gusanga u Rwanda rwariyubatse.',\n",
       "  'berita yanyuzwe no gusanga u rwanda rwariyubatse '),\n",
       " ('Bwana Weah azasimbura Ellen Johnson Sirleaf ku butegetsi mu kwezi gutaha.',\n",
       "  'bwana weah azasimbura ellen johnson sirleaf ku butegetsi mu kwezi gutaha '),\n",
       " ('Byaba ngombwa na Mushikiwabo bikamuviramo ibibazo.',\n",
       "  'byaba ngombwa na mushikiwabo bikamuviramo ibibazo '),\n",
       " ('Anko ositini yatangiye gukina amafilimi mu yiswe Imbarutso',\n",
       "  'anko ositini yatangiye gukina amafilimi mu yiswe imbarutso '),\n",
       " ('Lil G yifashishije Marina muri iyi ndirimbo.',\n",
       "  'lil g yifashishije marina muri iyi ndirimbo '),\n",
       " ('Umuziki ntabwo utuma umwana aba umuswa mu ishuri.',\n",
       "  'umuziki ntabwo utuma umwana aba umuswa mu ishuri '),\n",
       " ('Mu myandikire y’amateka ayariyo yose, amatariki y’ingenzi ku byabaye ni ngombwa.',\n",
       "  \"mu myandikire y'amateka ayariyo yose amatariki y'ingenzi ku byabaye ni ngombwa \"),\n",
       " ('Igitaramo Healing worship team igiye gukora.',\n",
       "  'igitaramo healing worship team igiye gukora '),\n",
       " ('Ibyo bavuze ni byinshi, byazagira igihe cyabyo cyo kubivuga.',\n",
       "  'ibyo bavuze ni byinshi byazagira igihe cyabyo cyo kubivuga '),\n",
       " ('Ni izina ry’abahungu rikomoka ku rurimi rw’Ikilatini rikaba risobanura “Ubohotse”.',\n",
       "  \"ni izina ry'abahungu rikomoka ku rurimi rw'ikilatini rikaba risobanura ubohotse \"),\n",
       " ('Guverineri Bosenibamwe yaremye agatima abarokotse Jenoside benda kugubwaho n’amazu',\n",
       "  \"guverineri bosenibamwe yaremye agatima abarokotse jenoside benda kugubwaho n'amazu \"),\n",
       " ('Muvaneho ingingo ikumira umuhanzi kubera imyaka.',\n",
       "  'muvaneho ingingo ikumira umuhanzi kubera imyaka '),\n",
       " ('Ashobora cyane ibijyanye no kuyobora cyangwa gucunga abantu cyangwa ibintu.',\n",
       "  'ashobora cyane ibijyanye no kuyobora cyangwa gucunga abantu cyangwa ibintu '),\n",
       " ('Sekaganda ni umuturanyi wanjye.', 'sekaganda ni umuturanyi wanjye '),\n",
       " ('Ubuyobozi bwa gereza ya Nyarugenge buvuga ko Mugesera abayeho neza nta kibazo.',\n",
       "  'ubuyobozi bwa gereza ya nyarugenge buvuga ko mugesera abayeho neza nta kibazo '),\n",
       " ('Amakuru ava muri Tanzania aravuga ko amasezerano bari bafitanye yamaze guseswa.',\n",
       "  'amakuru ava muri tanzania aravuga ko amasezerano bari bafitanye yamaze guseswa '),\n",
       " ('\"Inshuti n\\'abavandimwe b\\'umusore n\\'umukobwa bari babukereye.\"',\n",
       "  \"inshuti n'abavandimwe b'umusore n'umukobwa bari babukereye \"),\n",
       " ('Ni na ko kumije abantu cyane kurusha ukwa mbere.',\n",
       "  'ni na ko kumije abantu cyane kurusha ukwa mbere '),\n",
       " ('\"Twakinye n\\'umugwi wa mbere kandi dukina neza n\\'ishaka ryinshi.\"',\n",
       "  \"twakinye n'umugwi wa mbere kandi dukina neza n'ishaka ryinshi \"),\n",
       " ('Abandi ni abanyapolitiki bari mu nzego za Leta bataragera mu zabukuru.',\n",
       "  'abandi ni abanyapolitiki bari mu nzego za leta bataragera mu zabukuru '),\n",
       " ('Jay Polly hano yaririmbiraga mu Kinigi.',\n",
       "  'jay polly hano yaririmbiraga mu kinigi '),\n",
       " ('Patrick Nyamvumba na Minisitiri w’Ubutegetsi bw’Igihugu, Francis Kaboneka.',\n",
       "  \"patrick nyamvumba na minisitiri w'ubutegetsi bw'igihugu francis kaboneka \"),\n",
       " ('Murekatete n’umugabo we ngo bafite icyizere ko bazabyara .',\n",
       "  \"murekatete n'umugabo we ngo bafite icyizere ko bazabyara \"),\n",
       " ('\"Ubwo yavugaga ijambo nyuma gato y\\'iyo ntsinzi, yagize ati:.\"',\n",
       "  \"ubwo yavugaga ijambo nyuma gato y'iyo ntsinzi yagize ati \"),\n",
       " ('\"Uwo muco ntiwemewe n\\'amategeko muri Uganda.\"',\n",
       "  \"uwo muco ntiwemewe n'amategeko muri uganda \"),\n",
       " ('Mani Martin mu gitaramo cya Mibirizi.',\n",
       "  'mani martin mu gitaramo cya mibirizi '),\n",
       " ('Zimwe mu ndirimbo ze ni :.', 'zimwe mu ndirimbo ze ni '),\n",
       " ('Jack B uzwi mu njyana ya RnB akaba n’umuhanga mu kubyina.',\n",
       "  \"jack b uzwi mu njyana ya rnb akaba n'umuhanga mu kubyina \"),\n",
       " ('Intego yawo ni ukongera ubufatanye mu bihugu biwugize hagamijwe inyungu zisangiwe.',\n",
       "  'intego yawo ni ukongera ubufatanye mu bihugu biwugize hagamijwe inyungu zisangiwe '),\n",
       " ('Izibura imitsi yo ku gitsina bigatuma ushyukwa neza.',\n",
       "  'izibura imitsi yo ku gitsina bigatuma ushyukwa neza '),\n",
       " ('U Rwanda rushobora kwigirwaho kurwanya ruswa.',\n",
       "  'u rwanda rushobora kwigirwaho kurwanya ruswa '),\n",
       " ('Danny Usengimana yahise yegukana umupira, bagenzi be bawusinyaho .',\n",
       "  'danny usengimana yahise yegukana umupira bagenzi be bawusinyaho '),\n",
       " ('\"Reba amashusho y\\'indirimbo \\'Pole pole\\' yafatanije na Dany Nanone.\"',\n",
       "  \"reba amashusho y'indirimbo pole pole yafatanije na dany nanone \"),\n",
       " ('Ubu imaze kuba imyaka cumi n’ingahe.',\n",
       "  \"ubu imaze kuba imyaka cumi n'ingahe \"),\n",
       " ('Kamali yavuze ko bazazenguruka mu gihugu hose, muri buri Ntara bagatoranyamo batatu bahiga abandi.',\n",
       "  'kamali yavuze ko bazazenguruka mu gihugu hose muri buri ntara bagatoranyamo batatu bahiga abandi '),\n",
       " ('Abanyeshuli ba kaminuza biga amasaha make.',\n",
       "  'abanyeshuli ba kaminuza biga amasaha make '),\n",
       " ('Daily Monitor yatangaje ko igabanyuka ry’ uyu musoro ryatewe nuko abaturage bari bawamaganiye kure.',\n",
       "  'daily monitor yatangaje ko igabanyuka ry uyu musoro ryatewe nuko abaturage bari bawamaganiye kure '),\n",
       " ('Biravugwa ko hapfuye abantu benshi cyane hakarokora agahinja gusa.',\n",
       "  'biravugwa ko hapfuye abantu benshi cyane hakarokora agahinja gusa '),\n",
       " ('Ati “Gacaca yashyizweho n’igihugu kandi yubahwa hose.',\n",
       "  \"ati gacaca yashyizweho n'igihugu kandi yubahwa hose \"),\n",
       " ('Ntabwo twakwemerera izo komisiyo kugenda kuko nta bushobozi buhari.',\n",
       "  'ntabwo twakwemerera izo komisiyo kugenda kuko nta bushobozi buhari '),\n",
       " ('Active ngo “uyu mukobwa afite udukoryo twinshi”.',\n",
       "  'active ngo uyu mukobwa afite udukoryo twinshi '),\n",
       " ('Komeza imihigo Rwanda.', 'komeza imihigo rwanda '),\n",
       " ('Nyuma y’intsinzi, Umutoza Muhenuka Henry yagize ati;” Umukino twari tubizi ko utaza koroha.',\n",
       "  \"nyuma y'intsinzi umutoza muhenuka henry yagize ati umukino twari tubizi ko utaza koroha \"),\n",
       " ('Yakomeje agize ati “Kuvugira kuri telefone ni kimwe mu makosa atera uburangare.',\n",
       "  'yakomeje agize ati kuvugira kuri telefone ni kimwe mu makosa atera uburangare '),\n",
       " ('Ibi bikagaragaza ko badakorana n’abifite gusa.',\n",
       "  \"ibi bikagaragaza ko badakorana n'abifite gusa \"),\n",
       " ('Niba mwarimu atazi kuvuga Icyongereza, umunyeshuri we byifashe bite?.',\n",
       "  'niba mwarimu atazi kuvuga icyongereza umunyeshuri we byifashe bite '),\n",
       " ('Kuvuga ngo umuforomo arakora akazi k’umu-‘pharmacien’, umuganga arakora akazi k’umu ‘pharmacien’.',\n",
       "  \"kuvuga ngo umuforomo arakora akazi k'umu pharmacien umuganga arakora akazi k'umu pharmacien \"),\n",
       " ('Gucika intege umubiri wose ugahinda umuriro, kubira ibyuya byinshi ndetse no kugira umunabi.',\n",
       "  'gucika intege umubiri wose ugahinda umuriro kubira ibyuya byinshi ndetse no kugira umunabi ')]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(valid_dataset['sentence'][:100], valid_dataset['text'][:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'COMBINING ACUTE TONE MARK'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata\n",
    "unicodedata.name('́')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': 0,\n",
       " 'd': 1,\n",
       " 's': 2,\n",
       " 'n': 3,\n",
       " 'c': 4,\n",
       " 'l': 5,\n",
       " 'h': 6,\n",
       " 'w': 7,\n",
       " 'u': 8,\n",
       " 'z': 9,\n",
       " 't': 11,\n",
       " 'g': 12,\n",
       " 'j': 13,\n",
       " 'm': 14,\n",
       " 'o': 15,\n",
       " 'e': 16,\n",
       " 'k': 17,\n",
       " 'r': 18,\n",
       " 'i': 19,\n",
       " 'b': 20,\n",
       " 'f': 21,\n",
       " 'a': 22,\n",
       " 'v': 23,\n",
       " 'p': 24,\n",
       " '|': 10,\n",
       " '[UNK]': 25,\n",
       " '[PAD]': 26,\n",
       " '<s>': 27,\n",
       " '</s>': 28}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "import os\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/checkpoints/lg/wav2vec2-large-xlsr-lg-augment/checkpoint-4096'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_last_checkpoint(\"/workspace/checkpoints/lg/wav2vec2-large-xlsr-lg-augment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir=\"/workspace/checkpoints/lg/wav2vec2-large-xlsr-lg-augment/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for last checkpoint in /workspace/checkpoints/lg/wav2vec2-large-xlsr-lg-augment/\n",
      "Checkpoint detected, resuming training at /workspace/checkpoints/lg/wav2vec2-large-xlsr-lg-augment/checkpoint-4096. To avoid this behavior, change the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\n"
     ]
    }
   ],
   "source": [
    "last_checkpoint = None\n",
    "if os.path.isdir(output_dir) and True and not False:\n",
    "    print(f\"Looking for last checkpoint in {output_dir}\")\n",
    "    last_checkpoint = get_last_checkpoint(output_dir)\n",
    "    if last_checkpoint is None and len(os.listdir(output_dir)) > 0:\n",
    "        raise ValueError(\n",
    "            f\"Output directory ({output_dir}) already exists and is not empty. \"\n",
    "            \"Use --overwrite_output_dir to overcome.\"\n",
    "        )\n",
    "    elif last_checkpoint is not None:\n",
    "        print(\n",
    "            f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"\n",
    "            \"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isdir(output_dir) and True and not False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import torchaudio\n",
    "import soundfile\n",
    "from audiomentations import Compose, AddGaussianNoise, Gain, PitchShift, Shift\n",
    "\n",
    "resampler = torchaudio.transforms.Resample(48_000, 16_000)\n",
    "\n",
    "augment = Compose([\n",
    "    AddGaussianNoise(min_amplitude=0.0001, max_amplitude=0.01, p=1),\n",
    "    PitchShift(min_semitones=-3, max_semitones=3, p=0.8),\n",
    "    Gain(min_gain_in_db=-6, max_gain_in_db=6, p=0.8),\n",
    "    Shift(min_fraction=-0.5, max_fraction=0.5, p=0.8),\n",
    "])\n",
    "\n",
    "def speech_file_to_array_fn_torchaudio(batch):\n",
    "    speech_array, sampling_rate = torchaudio.load(batch[\"path\"])\n",
    "    batch[\"speech\"] = resampler(speech_array).squeeze().numpy()\n",
    "    batch[\"sampling_rate\"] = 16_000\n",
    "    return batch\n",
    "\n",
    "def speech_file_to_array_fn_librosa(batch):\n",
    "    speech_array, sample_rate = torchaudio.load(batch[\"path\"])\n",
    "    batch[\"speech\"] = librosa.resample(speech_array.squeeze().numpy(), sample_rate, 16_000)\n",
    "    return batch\n",
    "\n",
    "def augmented_speech_file_to_array_fn(batch):\n",
    "    try:\n",
    "        speech_array, sampling_rate = soundfile.read(batch[\"path\"] + \"-augmented.wav\")\n",
    "    except:\n",
    "        speech_array, sampling_rate = torchaudio.load(batch[\"path\"])\n",
    "        speech_array = resampler(speech_array)\n",
    "        speech_array = augment(samples=speech_array, sample_rate=sampling_rate).squeeze()\n",
    "        soundfile.write(batch[\"path\"]+\"-augmented.wav\", speech_array, sampling_rate, subtype='PCM_24')\n",
    "\n",
    "    batch[\"speech\"] = speech_array\n",
    "    batch[\"sampling_rate\"] = 16_000\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accent': '',\n",
       " 'age': '',\n",
       " 'client_id': 'a0c75a2b3ef19a055ebcc7587ebf341614373519ceb63f67e67e4eae0eb4858dc2031cd42b08b389168e6c84bce198dc8f7405fdb443195eaaf6cd7dc981425c',\n",
       " 'down_votes': 1,\n",
       " 'gender': '',\n",
       " 'locale': 'rw',\n",
       " 'path': '/workspace/raw_data/rw/downloads/extracted/6755b117c96a17977cf94d8a118d06e13daa8d123092dfaa6ccb5bd13f06e60f/cv-corpus-6.1-2020-12-11/rw/clips/common_voice_rw_22948194.mp3',\n",
       " 'segment': \"''\",\n",
       " 'sentence': 'ni uko batari bagiha agaciro isanduku n’ibyo yavuze ku ri bo',\n",
       " 'up_votes': 2,\n",
       " 'speech': array([ 0.        ,  0.        ,  0.        , ..., -0.00116267,\n",
       "        -0.00045365, -0.00068105], dtype=float32)}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speech_file_to_array_fn_librosa(test_dataset[23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accent': '',\n",
       " 'age': '',\n",
       " 'client_id': 'a0c75a2b3ef19a055ebcc7587ebf341614373519ceb63f67e67e4eae0eb4858dc2031cd42b08b389168e6c84bce198dc8f7405fdb443195eaaf6cd7dc981425c',\n",
       " 'down_votes': 1,\n",
       " 'gender': '',\n",
       " 'locale': 'rw',\n",
       " 'path': '/workspace/raw_data/rw/downloads/extracted/6755b117c96a17977cf94d8a118d06e13daa8d123092dfaa6ccb5bd13f06e60f/cv-corpus-6.1-2020-12-11/rw/clips/common_voice_rw_22948195.mp3',\n",
       " 'segment': \"''\",\n",
       " 'sentence': 'amata kwera zari zikeye mu maso kurusha',\n",
       " 'up_votes': 2,\n",
       " 'speech': array([-0.43122205, -0.42071682, -0.4279239 , ..., -0.4282133 ,\n",
       "        -0.4141648 , -0.3871291 ], dtype=float32),\n",
       " 'sampling_rate': 16000}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_speech_file_to_array_fn(test_dataset[24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05630261, -0.03208497, -0.05551476, ...,  0.00743804,\n",
       "       -0.00030689, -0.08274259], dtype=float32)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_speech_file_to_array_fn(test_dataset[24])['speech'].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a1c616bb5a4d68add6c51777b82b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4717.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-152-61b66947f401>\u001b[0m in \u001b[0;36maugmented_speech_file_to_array_fn\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0;31m#speech_array, sampling_rate = soundfile.read(batch[\"path\"] + \"-augmented.wav\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-156-ff6de73deca8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maugmented_speech_file_to_array_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint)\u001b[0m\n\u001b[1;32m   1425\u001b[0m                 \u001b[0mfn_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1426\u001b[0m                 \u001b[0mnew_fingerprint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_fingerprint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1427\u001b[0;31m                 \u001b[0mupdate_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdate_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1428\u001b[0m             )\n\u001b[1;32m   1429\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m         }\n\u001b[1;32m    202\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;31m# re-apply format to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/fingerprint.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Call actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;31m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_map_single\u001b[0;34m(self, function, with_indices, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, update_data)\u001b[0m\n\u001b[1;32m   1682\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1684\u001b[0;31m                         \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_function_on_filtered_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1685\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mupdate_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1686\u001b[0m                             \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast_to_python_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mapply_function_on_filtered_inputs\u001b[0;34m(inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   1606\u001b[0m                 \u001b[0meffective_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m             processed_inputs = (\n\u001b[0;32m-> 1608\u001b[0;31m                 \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meffective_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mwith_indices\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1609\u001b[0m             )\n\u001b[1;32m   1610\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mupdate_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-152-61b66947f401>\u001b[0m in \u001b[0;36maugmented_speech_file_to_array_fn\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mspeech_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mspeech_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeech_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mspeech_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspeech_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampling_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0msoundfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"-augmented.wav\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspeech_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'PCM_24'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/audiomentations/core/composition.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, samples, sample_rate)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/audiomentations/core/transforms_interface.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, samples, sample_rate)\u001b[0m\n\u001b[1;32m     74\u001b[0m                     )\n\u001b[1;32m     75\u001b[0m                 )\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/audiomentations/augmentations/transforms.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, samples, sample_rate)\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mpitch_shifted_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0msample_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     \u001b[0mn_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_semitones\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m                 )\n\u001b[1;32m    330\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/librosa/effects.py\u001b[0m in \u001b[0;36mpitch_shift\u001b[0;34m(y, sr, n_steps, bins_per_octave, res_type, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0;31m# Stretch in time, then resample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     y_shift = core.resample(\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mtime_stretch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m     )\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mresample\u001b[0;34m(y, orig_sr, target_sr, res_type, fix, scale, **kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamplerate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconverter_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresampy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_sr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_sr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/resampy/core.py\u001b[0m in \u001b[0;36mresample\u001b[0;34m(x, sr_orig, sr_new, axis, filter, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mx_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0my_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0mresample_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterp_win\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterp_delta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_dataset.map(augmented_speech_file_to_array_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
